{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "d10ac11a",
      "metadata": {
        "id": "d10ac11a"
      },
      "source": [
        "# Amazon product ratings prediction"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1528011b",
      "metadata": {
        "id": "1528011b"
      },
      "source": [
        "Mission:    Create a web that'll recommend the top 5 products based on predicted ratings."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3c418f48",
      "metadata": {
        "id": "3c418f48"
      },
      "source": [
        "*italicized text*# Import libraries and my own functions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "d67c88aa",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2024-01-04T20:46:40.995273900Z",
          "start_time": "2024-01-04T20:46:32.874240700Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 397
        },
        "id": "d67c88aa",
        "outputId": "e71e9278-a984-4423-faac-ddd228bbea78"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "ModuleNotFoundError",
          "evalue": "No module named 'training'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-2-a66863006cf5>\u001b[0m in \u001b[0;36m<cell line: 16>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc_dir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtraining\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mutils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mEDA\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'training'",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ],
          "errorDetails": {
            "actions": [
              {
                "action": "open_url",
                "actionText": "Open Examples",
                "url": "/notebooks/snippets/importing_libraries.ipynb"
              }
            ]
          }
        }
      ],
      "source": [
        "import sys\n",
        "import os\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "# Get the current working directory\n",
        "current_dir = os.getcwd()\n",
        "\n",
        "# Construct the path to the 'src' directory\n",
        "src_dir = os.path.join(current_dir, 'src')\n",
        "\n",
        "# Add 'src' directory to the sys.path\n",
        "sys.path.append(src_dir)\n",
        "\n",
        "from training import *\n",
        "from utils import *\n",
        "from EDA import *\n",
        "\n",
        "# Show all columns (don't replace some with \"...\")\n",
        "pd.set_option('display.max_columns', None)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f8028c61",
      "metadata": {
        "id": "f8028c61"
      },
      "source": [
        "# Import data"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9f648118",
      "metadata": {
        "id": "9f648118"
      },
      "source": [
        "## Download dataset from kaggle"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "2f67263f",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2024-01-04T20:46:41.279672800Z",
          "start_time": "2024-01-04T20:46:40.984782300Z"
        },
        "id": "2f67263f"
      },
      "outputs": [],
      "source": [
        "#!pip install kaggle"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "301f9220",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2024-01-04T20:46:41.358321200Z",
          "start_time": "2024-01-04T20:46:41.251293400Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "301f9220",
        "outputId": "c33b4340-0911-46cd-95af-d195402bc475"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['.config', 'sample_data']"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ],
      "source": [
        "os.listdir()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "4a69367f",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2024-01-04T20:46:49.447126Z",
          "start_time": "2024-01-04T20:46:41.346283100Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 369
        },
        "id": "4a69367f",
        "outputId": "3b279a86-a7c1-481c-def0-36730e5a4ba5"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "OSError",
          "evalue": "Could not find kaggle.json. Make sure it's located in /root/.kaggle. Or use the environment method.",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-5-f0c540724888>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mkaggle\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpandas\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mzipfile\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/kaggle/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mapi\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mKaggleApi\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mApiClient\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0mapi\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauthenticate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/kaggle/api/kaggle_api_extended.py\u001b[0m in \u001b[0;36mauthenticate\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    396\u001b[0m                 \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    397\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 398\u001b[0;31m                 raise IOError('Could not find {}. Make sure it\\'s located in'\n\u001b[0m\u001b[1;32m    399\u001b[0m                               ' {}. Or use the environment method.'.format(\n\u001b[1;32m    400\u001b[0m                                   self.config_file, self.config_dir))\n",
            "\u001b[0;31mOSError\u001b[0m: Could not find kaggle.json. Make sure it's located in /root/.kaggle. Or use the environment method."
          ]
        }
      ],
      "source": [
        "import kaggle\n",
        "import pandas as pd\n",
        "import zipfile\n",
        "import os\n",
        "\n",
        "\n",
        "data_path = 'amazon_reviews.csv'\n",
        "\n",
        "if not 'amazon_reviews.csv' in os.listdir():\n",
        "    # Download dataset\n",
        "    kaggle.api.dataset_download_files('rogate16/amazon-reviews-2018-full-dataset', path='.', unzip=True)\n",
        "\n",
        "    # Assuming the file is a CSV, find the downloaded CSV file\n",
        "    for file in os.listdir('.'):\n",
        "        if file.endswith('.csv'):\n",
        "            data_path = file\n",
        "            break\n",
        "\n",
        "# Load into Pandas DataFrame\n",
        "df = pd.read_csv(data_path)\n",
        "df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b65caf4f",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2024-01-04T20:46:49.466975100Z",
          "start_time": "2024-01-04T20:46:49.384290300Z"
        },
        "id": "b65caf4f"
      },
      "outputs": [],
      "source": [
        "df.head(10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "09a98902",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2024-01-04T20:46:49.684598200Z",
          "start_time": "2024-01-04T20:46:49.397870400Z"
        },
        "id": "09a98902"
      },
      "outputs": [],
      "source": [
        "df_small = df.sample(10000)\n",
        "orig_cols = df.columns"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "dd5fa2b6",
      "metadata": {
        "id": "dd5fa2b6"
      },
      "source": [
        "# Some domain information and prior research"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "499abf8f",
      "metadata": {
        "id": "499abf8f"
      },
      "source": [
        "## on the dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "fc4617cd",
      "metadata": {
        "id": "fc4617cd"
      },
      "source": [
        "About Dataset\n",
        "This dataset was collected from an open-source Amazon reviews made available by Jianmo Ni\n",
        "\n",
        "Preprocess\n",
        "The data was originally in JSON, and divided into metadata and reviews. I converted the data into data frame and then join both the metadata and the reviews, before converting it to CSV file. No further process was done afterwards.\n",
        "\n",
        "Content\n",
        "This dataset contains full reviews from Amazon in 2018, consists of 500000+ reviews from 100000+ users. The columns are pretty much self-explanatory, such as userName, itemName, rating, reviewText, etc\n",
        "\n",
        "Task\n",
        "This dataset can be used to build a recommender system, since it has the user-item-rating information. This can also be used for NLP tasks, using the reviewText column."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "14a60ac1",
      "metadata": {
        "id": "14a60ac1"
      },
      "source": [
        "The \"Amazon Reviews 2018 Full Dataset\" on Kaggle is a comprehensive collection of Amazon product reviews from the year 2018. This dataset is extensive and is likely to include various features such as the text of the reviews, ratings, product information, user details, and timestamps. It is typically used for analysis in natural language processing, sentiment analysis, and building recommendation systems."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d45c3f03",
      "metadata": {
        "id": "d45c3f03"
      },
      "source": [
        "## ## Should we check if there's any time trend in here?"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "aed9ef70",
      "metadata": {
        "id": "aed9ef70"
      },
      "source": [
        "Research on predicting the helpfulness of Amazon product reviews indicates that the most effective features often include content-based aspects of the reviews. These features span categories like lexical, structural, semantic, syntactic, and metadata elements. Key features identified as impactful include review length, unigrams (single words), product ratings, and the degree of detail, which is a function of review length and n-grams. Additionally, features like sentiment analysis, readability, and text surface elements (like the number of words, sentences, and use of punctuation) also play significant roles. The selection of these features, however, can be domain- and platform-dependent, and the effectiveness of individual features or combinations can vary​​."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b8241677",
      "metadata": {
        "id": "b8241677"
      },
      "source": [
        "## ## A medium article: Amazon Review Rating Prediction with NLP\n",
        "https://medium.com/data-science-lab-spring-2021/amazon-review-rating-prediction-with-nlp-28a4acdd4352\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "08228156",
      "metadata": {
        "id": "08228156"
      },
      "source": [
        "## #  decided to consider reviews written by verified purchasers to decrease the risk of fraudulent reviews with dubious ratings"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "68ed9b9e",
      "metadata": {
        "id": "68ed9b9e"
      },
      "source": [
        "## # Only star_rating, review_headline, and review_body columns were considered to reduce feature complexity."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8180e389",
      "metadata": {
        "id": "8180e389"
      },
      "source": [
        "## # review_headline and review_body were concatenated and delimited by a space to further reduce feature complexity"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2c1616b7",
      "metadata": {
        "id": "2c1616b7"
      },
      "source": [
        "## # Normalize the dataset by converting all the characters to lowercase."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a3f0d92d",
      "metadata": {
        "id": "a3f0d92d"
      },
      "source": [
        "## # convert all whitespace and punctuation into a single space to get rid of any inconsistencies"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1acc4ea4",
      "metadata": {
        "id": "1acc4ea4"
      },
      "source": [
        "## #  regex to write a de-contract method that essentially finds and replaces the apostrophe-letter format into a full word. We made an observation that replacing “n’t” to “not” is not viable in all cases. It works for “isn’t” ⇒ “is not” but will break “can’t” ⇒ “ca not”. We created special cases for these situations."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8349537c",
      "metadata": {
        "id": "8349537c"
      },
      "source": [
        "## # remove stopwords to further denoise the input. We used NLTK’s stopwords package to provide us with the list of stopwords. Here, we made an adjustment to avoid the removal of certain negation stop words, namely“not” and “no”, since they do indeed influence sentence meaning. A product that is “not good” is certainly different from a “good” product."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "bae63e47",
      "metadata": {
        "id": "bae63e47"
      },
      "source": [
        "## # Lemmatization: pre-computed embeddings seem to be calculated without stemming so we decided against stemming in preprocessing as well.  "
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c2225f77",
      "metadata": {
        "id": "c2225f77"
      },
      "source": [
        "## ## Treating Numbers: considered converting alphanumeric numbers into English words for the sake of consistency. decided we would just keep the original format instead."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b0c88bb5",
      "metadata": {
        "id": "b0c88bb5"
      },
      "source": [
        "### # Stemming: could provide some inaccurate results."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "bad46934",
      "metadata": {
        "id": "bad46934"
      },
      "source": [
        "## ## Embeddings: little significant difference in model performance for the simpler encoding schemes like Bag of Words and TF-IDF. However, the pre-computed word-based embeddings performed the best, specifically BERT, which is a pre-computed NLP model from Google that had to be optimized via stochastic gradient descent."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2390099e",
      "metadata": {
        "id": "2390099e"
      },
      "source": [
        "## ## Modeling:"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6ea9c6f2",
      "metadata": {
        "id": "6ea9c6f2"
      },
      "source": [
        "## ### tried a few classification models, although these were quickly proven to be vastly inferior to regression models, based on the nature of the project. Our unsupervised deep learning models employed a variety of the aforementioned embeddings.m"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "adcfadaa",
      "metadata": {
        "id": "adcfadaa"
      },
      "source": [
        "## ### used Root-Mean-Square Error (RMSE) as our loss metric, which would tell us on average how many stars away our label was from the actual value"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "41b6ffa9",
      "metadata": {
        "id": "41b6ffa9"
      },
      "source": [
        "## ### normalized the labels to be from 0 to 1 instead of 1 to 5 by dividing all ratings by five. This means a label of 0.2 equals 1 star, 0.4 equals 2 stars, etc. An RMSE value of 0.1 suggests our labels are predicting a half star away from their actual value, on average. As we will talk about in the shortcomings section, it is virtually impossible to get a test RMSE value close to 0 based on the nature of the problem."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "bdeae6c8",
      "metadata": {
        "id": "bdeae6c8"
      },
      "source": [
        "## ### LightGBM: Baseline for regression RMSE, we encoded the review text with TF-IDF and fit an untuned Light GBM Regression model. . The RMSE value on the test set was 0.178, aka an average of 0.89 stars away from the actual review value"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "981510a4",
      "metadata": {
        "id": "981510a4"
      },
      "source": [
        "## ### Catboost: We decided to implement a Bag of Words model as we were curious about how well such a model would predict the rating of a review...  a CatBoost regression model on our augmented training dataset for 100 iterations, which gave us an RMSE of about 0.17 on the test dataset, which was comparable to the RMSE we received from one of our better-performing models."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f6fa0cdf",
      "metadata": {
        "id": "f6fa0cdf"
      },
      "source": [
        "## ### ReLU: we achieved an RMSE of 0.173 on the test set. We could add l1 and l2 regularization or dropout layers to discourage overfitting, but we decided against this as this model will act as a baseline for comparison of other models."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7fd0f5b4",
      "metadata": {
        "id": "7fd0f5b4"
      },
      "source": [
        "## ### 1D Convolution Layer: achieved an RMSE of 0.160 on the test set."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1032cd46",
      "metadata": {
        "id": "1032cd46"
      },
      "source": [
        "## ### LSTM/GRU: We achieved 0.142 testing loss"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2ac7ed2b",
      "metadata": {
        "id": "2ac7ed2b"
      },
      "source": [
        "## ### BERT: Once applied to the test set, the RMSE loss was 0.136"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f94656cf",
      "metadata": {
        "id": "f94656cf"
      },
      "source": [
        "## ## Shortcomings:\n",
        "## ### different people associate star ratings with different sentiment polarities, especially for the 2-, 3-, and 4-star ratings\n",
        "## ###  we divided all ratings by five in order to standardize true labels between zero and one. However, we realized afterward that this approach improperly restricts predicted ratings that exceed five stars\n",
        "## ### For the less advanced models, double negation and mixed sentiment was sometimes not factored into the predicted label as much as it should have been. Models that accounted for bi-directional representation did the best with this topic.\n",
        "## ### Capitalization: The sentence “I did NOT like the product” should likely be labeled with a lower rating than the sentence “I did not like the product.”"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "094f1d93",
      "metadata": {
        "id": "094f1d93"
      },
      "source": [
        "## ### Conclustion: Future work could build on these models by increasing the training set, improving pre-processing, and accounting for the shortcomings listed above as best as possible. One could also download a more sizable version of BERT, although computing time would rapidly increase."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "54cabb5f",
      "metadata": {
        "id": "54cabb5f"
      },
      "source": [
        "## ## Potential features:\n",
        "## # Sentiment of review\n",
        "https://towardsdatascience.com/predicting-sentiment-of-amazon-product-reviews-6370f466fa73\n",
        "https://www.kaggle.com/code/imdevskp/amazon-reviews-sentiment-analysis-and-prediction"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f42f620c",
      "metadata": {
        "id": "f42f620c"
      },
      "source": [
        "## # Mean ratings that connected users gave to this item - but can we rely on having other ratings?\n",
        "https://www.kaggle.com/code/tsefongwon/graph-analysis-of-amazon-customer-buying-habits/notebook"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7ca79c43",
      "metadata": {
        "id": "7ca79c43"
      },
      "source": [
        "## # Visual features of the item\n",
        "## # Cosine Similarity of this item to other items - but can we rely on having other ratings?\n",
        "https://www.kaggle.com/code/tsefongwon/graph-analysis-of-amazon-customer-buying-habits/notebook"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "19eabf6e",
      "metadata": {
        "id": "19eabf6e"
      },
      "source": [
        "## # prior multi-classification of negative (1-2), neutral (3) and positive (4-5) reviews:\n",
        "https://medium.com/@jenny6449/predict-the-ratings-of-amazon-products-based-on-customer-reviews-using-machine-learning-b035bcb1c17e"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4728e5cb",
      "metadata": {
        "id": "4728e5cb"
      },
      "source": [
        "# Define target"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "18561a01",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2024-01-04T20:46:49.768452400Z",
          "start_time": "2024-01-04T20:46:49.444969300Z"
        },
        "id": "18561a01"
      },
      "outputs": [],
      "source": [
        "df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "485068c7",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2024-01-04T20:46:50.213757100Z",
          "start_time": "2024-01-04T20:46:49.474613200Z"
        },
        "id": "485068c7"
      },
      "outputs": [],
      "source": [
        "target = 'rating'\n",
        "plot_target_bar(df, target)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d1d7bea8",
      "metadata": {
        "id": "d1d7bea8"
      },
      "source": []
    },
    {
      "cell_type": "markdown",
      "id": "3a991831",
      "metadata": {
        "id": "3a991831"
      },
      "source": [
        "## # Target is unblanaced towrads 5 ratings - more than 70%"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4fadee5d",
      "metadata": {
        "id": "4fadee5d"
      },
      "source": [
        "# Define the problem"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "67f1de27",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2024-01-04T20:46:50.265669400Z",
          "start_time": "2024-01-04T20:46:49.766829600Z"
        },
        "id": "67f1de27"
      },
      "outputs": [],
      "source": [
        "n = 5\n",
        "one_user = df.iloc[n].userName\n",
        "df.iloc[n]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8614b37c",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2024-01-04T20:46:50.357873200Z",
          "start_time": "2024-01-04T20:46:49.780972500Z"
        },
        "id": "8614b37c"
      },
      "outputs": [],
      "source": [
        "df[df['userName'] == one_user].T"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ca012b53",
      "metadata": {
        "id": "ca012b53"
      },
      "source": [
        "## When given userName, recommend 5 highest predicted ratings.\n",
        "## The predicted ratings are based on the user's history of ratings, which includes features on the items the user has rated before.\n",
        "## Assumption 1: verified userNames uniquely identify users (otherwise the user would have to manually fill in his ratings history when asking for recommendation).\n",
        "## Assumption 2: The user doesn't need to us recommend on items she has already rated as good, so we'll not recommend on them.\n",
        "## Assumption 3: We cannot trust unverified ratings since an amazon seller can give low rating to his rivals items, and do so many times  \n",
        "## ** If userName doesn't exist (doesn't have rating's history), recommend on top 5 rated items for all users (add rating votes as a rating weight, 0 votes is 1, 1 votes is 2, 2 votes is 3, etc.)\n",
        "## ** The userNames \"Amazon Customer\" and \"Kindel Customers\" contain 7% of all ratings. While they are verified, they do not sound like legitimate users (not by name or number of review). Even though, we will respond to their recommendation request if they do so.  "
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5ab7b0d9",
      "metadata": {
        "id": "5ab7b0d9"
      },
      "source": [
        "#### # Since we are basing are model on historical recommendations, we'll drop items with less than 5 ratings\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9a8693de",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2024-01-04T20:46:50.479927800Z",
          "start_time": "2024-01-04T20:46:49.827826100Z"
        },
        "id": "9a8693de"
      },
      "outputs": [],
      "source": [
        "itemName_n_ratings = df.groupby('itemName').size()\n",
        "itemName_n_ratings.value_counts(normalize=True).sort_index()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "05497d15",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2024-01-04T20:46:50.521375900Z",
          "start_time": "2024-01-04T20:46:50.058451600Z"
        },
        "id": "05497d15"
      },
      "outputs": [],
      "source": [
        "item_n_ratings_threshold = 5\n",
        "itemName_n_ratings.value_counts(normalize=True)[itemName_n_ratings.value_counts(normalize=True).sort_index().index<item_n_ratings_threshold].sum()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6a30a371",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2024-01-04T20:46:50.854738800Z",
          "start_time": "2024-01-04T20:46:50.075438700Z"
        },
        "id": "6a30a371"
      },
      "outputs": [],
      "source": [
        "items_with_history = itemName_n_ratings[itemName_n_ratings>=item_n_ratings_threshold].index.tolist()\n",
        "df = df[df.itemName.isin(items_with_history)]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "721ee278",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2024-01-04T20:46:51.148546200Z",
          "start_time": "2024-01-04T20:46:50.212092800Z"
        },
        "id": "721ee278"
      },
      "outputs": [],
      "source": [
        "userNames_n_ratings = df.groupby('userName').size()\n",
        "userNames_n_ratings.value_counts(normalize=True).sort_index()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e9829a33",
      "metadata": {
        "id": "e9829a33"
      },
      "source": [
        "#### # Same for users - we have too much items, we'll drop items with less than 6 ratings\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c3810187",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2024-01-04T20:46:51.167976900Z",
          "start_time": "2024-01-04T20:46:50.381804100Z"
        },
        "id": "c3810187"
      },
      "outputs": [],
      "source": [
        "users_n_ratings_threshold = 6\n",
        "userNames_n_ratings.value_counts(normalize=True)[userNames_n_ratings.value_counts(normalize=True).sort_index().index<users_n_ratings_threshold].sum()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c8c5faaa",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2024-01-04T20:46:51.335020600Z",
          "start_time": "2024-01-04T20:46:50.394585200Z"
        },
        "id": "c8c5faaa"
      },
      "outputs": [],
      "source": [
        "users_with_history = userNames_n_ratings[userNames_n_ratings>=users_n_ratings_threshold].index.tolist()\n",
        "df = df[df.userName.isin(users_with_history)]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ad4a7034",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2024-01-04T20:46:51.387198500Z",
          "start_time": "2024-01-04T20:46:50.488640200Z"
        },
        "id": "ad4a7034"
      },
      "outputs": [],
      "source": [
        "df.shape, df[['userName', 'itemName']].nunique()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4b8cb0bf",
      "metadata": {
        "id": "4b8cb0bf"
      },
      "source": [
        "# Split to Train, Validation, Test"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7feef1ad",
      "metadata": {
        "id": "7feef1ad"
      },
      "source": [
        "#### # Split the dataset with 80% for train, 10% for val and 10% for test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1eeaa5f0",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2024-01-04T20:46:51.407629Z",
          "start_time": "2024-01-04T20:46:50.594555500Z"
        },
        "id": "1eeaa5f0"
      },
      "outputs": [],
      "source": [
        "target"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9382f6af",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2024-01-04T20:46:52.027232100Z",
          "start_time": "2024-01-04T20:46:50.612834600Z"
        },
        "id": "9382f6af"
      },
      "outputs": [],
      "source": [
        "test_size=0.1\n",
        "equal_val_test_size=True\n",
        "X_train, X_test, X_val, y_train, y_test, y_val = split_dataset(df, target_col=target, the_test_size=test_size, equal_val_test_size=equal_val_test_size)\n",
        "\n",
        "train = pd.concat([X_train, y_train], axis=1)\n",
        "val = pd.concat([X_val, y_val], axis=1)\n",
        "test = pd.concat([X_test, y_test], axis=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "55d792d6",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2024-01-04T20:46:52.173633200Z",
          "start_time": "2024-01-04T20:46:51.667218400Z"
        },
        "id": "55d792d6"
      },
      "outputs": [],
      "source": [
        "train['userName'].nunique(), val['userName'].nunique(), test['userName'].nunique(),"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "97b9b1ad",
      "metadata": {
        "id": "97b9b1ad"
      },
      "source": [
        "#### # Data is not stratified on userName - which is not good since we want to predict ratings for each user using his past ratings"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c450b990",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2024-01-04T20:47:17.248618Z",
          "start_time": "2024-01-04T20:46:51.712098900Z"
        },
        "id": "c450b990"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Set the split sizes for validation and test\n",
        "val_size = 0.1\n",
        "test_size = 0.1\n",
        "\n",
        "# Group the data by user\n",
        "grouped = df.groupby('userName')\n",
        "\n",
        "# Split each group and store in a list\n",
        "train_list, val_list, test_list = [], [], []\n",
        "for name, group in grouped:\n",
        "        user_train_val, user_test = train_test_split(group, test_size=test_size, random_state=42, shuffle=True)\n",
        "        user_train, user_val = train_test_split(user_train_val, test_size=val_size/(1-test_size), random_state=42, shuffle=True)\n",
        "\n",
        "        train_list.append(user_train)\n",
        "        val_list.append(user_val)\n",
        "        test_list.append(user_test)\n",
        "\n",
        "# Concatenate all splits\n",
        "train = pd.concat(train_list)\n",
        "val = pd.concat(val_list)\n",
        "test = pd.concat(test_list)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "aefd7910",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2024-01-04T20:47:17.325710100Z",
          "start_time": "2024-01-04T20:47:17.250832300Z"
        },
        "id": "aefd7910"
      },
      "outputs": [],
      "source": [
        "train['userName'].nunique(), val['userName'].nunique(), test['userName'].nunique(),"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2e69ac02",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2024-01-04T20:47:17.364002300Z",
          "start_time": "2024-01-04T20:47:17.281613900Z"
        },
        "id": "2e69ac02"
      },
      "outputs": [],
      "source": [
        "train.shape[0]/len(df), val.shape[0]/len(df), test.shape[0]/len(df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "07fefda1",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2024-01-04T20:47:17.448781600Z",
          "start_time": "2024-01-04T20:47:17.295230700Z"
        },
        "id": "07fefda1"
      },
      "outputs": [],
      "source": [
        "userNames_n_ratings = train.groupby('userName').size()\n",
        "userNames_n_ratings.value_counts(normalize=True).sort_index()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b8a2cc0a",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2024-01-04T20:47:17.598639400Z",
          "start_time": "2024-01-04T20:47:17.326767Z"
        },
        "id": "b8a2cc0a"
      },
      "outputs": [],
      "source": [
        "train.groupby(['itemName']).size().value_counts(normalize=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "57465569",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2024-01-04T20:47:17.770941800Z",
          "start_time": "2024-01-04T20:47:17.403008800Z"
        },
        "id": "57465569"
      },
      "outputs": [],
      "source": [
        "train['itemName'].value_counts().plot()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1bdbb0fe",
      "metadata": {
        "id": "1bdbb0fe"
      },
      "source": [
        "#### # We still have a long tail of item reviews, over 50% items with only one review. But that's OK -  if a user recommended has a similair user that rated a unique infrequent item, we'll still try to recommend on that item.    "
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4c9bd23b",
      "metadata": {
        "id": "4c9bd23b"
      },
      "source": [
        "# Exploratory  Data Analysis, pre-processing (and some feature engineering)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b3f7d2d0",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2024-01-04T20:47:17.841794400Z",
          "start_time": "2024-01-04T20:47:17.586723900Z"
        },
        "id": "b3f7d2d0"
      },
      "outputs": [],
      "source": [
        "train"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a40c7d81",
      "metadata": {
        "id": "a40c7d81"
      },
      "source": [
        "## Delve into the features"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b7e8b69e",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2024-01-04T20:47:18.251409900Z",
          "start_time": "2024-01-04T20:47:17.618029Z"
        },
        "id": "b7e8b69e"
      },
      "outputs": [],
      "source": [
        "train.describe(include='all')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cf93f74b",
      "metadata": {
        "id": "cf93f74b"
      },
      "source": [
        "### 1. Users"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d8535b86",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2024-01-04T20:47:18.495905300Z",
          "start_time": "2024-01-04T20:47:18.157208600Z"
        },
        "id": "d8535b86"
      },
      "outputs": [],
      "source": [
        "train.groupby(['userName']).size().describe()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "30dbfff5",
      "metadata": {
        "id": "30dbfff5"
      },
      "source": [
        "#### # There are 55k \"unique\" users, and a mean of 6.6 ratings per user and a median of 4 (right skewed)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d6e541c3",
      "metadata": {
        "id": "d6e541c3"
      },
      "source": [
        "#### # More precisely, the mean number of ratings per user is 4.2, with median of 2 (skewed to the right) - long tail of high amount of ratings, most users don't rate more than 3 items."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "13365c51",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2024-01-04T20:47:18.534693600Z",
          "start_time": "2024-01-04T20:47:18.187548900Z"
        },
        "id": "13365c51"
      },
      "outputs": [],
      "source": [
        "users_frequencies = get_col_frequencies(train, col_name='userName', sort_index=False)\n",
        "users_frequencies"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "51751ab1",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2024-01-04T20:47:18.671378800Z",
          "start_time": "2024-01-04T20:47:18.239804200Z"
        },
        "id": "51751ab1"
      },
      "outputs": [],
      "source": [
        "train[train.userName.isin(['Amazon Customer', 'Kindle Customer'])]['verified'].mean()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1b750d2d",
      "metadata": {
        "id": "1b750d2d"
      },
      "source": [
        "#### # there are 8% ratings Amazon and Kindel, and 97% of them are verified"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3a569f95",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2024-01-04T20:47:18.689647800Z",
          "start_time": "2024-01-04T20:47:18.310807100Z"
        },
        "id": "3a569f95"
      },
      "outputs": [],
      "source": [
        "train['verified'].mean()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a37bd931",
      "metadata": {
        "id": "a37bd931"
      },
      "source": [
        "#### # Drop the 5% unverified users: we cannot trust these ratings as true ratings"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ef879ae3",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2024-01-04T20:47:18.761867900Z",
          "start_time": "2024-01-04T20:47:18.327726600Z"
        },
        "id": "ef879ae3"
      },
      "outputs": [],
      "source": [
        "train = train[train['verified'] == True]\n",
        "val = val[val['verified'] == True]\n",
        "test = test[test['verified'] == True]\n",
        "assert train['verified'].mean() == 1"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d5077155",
      "metadata": {
        "id": "d5077155"
      },
      "source": [
        "#### # Drop verified col, as it contain same information for all"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "dab55e57",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2024-01-04T20:47:19.072547800Z",
          "start_time": "2024-01-04T20:47:18.403227800Z"
        },
        "id": "dab55e57"
      },
      "outputs": [],
      "source": [
        "train = train.drop(columns='verified')\n",
        "val = val.drop(columns='verified')\n",
        "test = test.drop(columns='verified')\n",
        "assert not 'verified' in train"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3a3a04f7",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2024-01-04T20:47:19.145458500Z",
          "start_time": "2024-01-04T20:47:18.464971Z"
        },
        "id": "3a3a04f7"
      },
      "outputs": [],
      "source": [
        "users_frequencies = get_col_frequencies(train, col_name='userName', sort_index=False)\n",
        "users_frequencies"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a06b052c",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2024-01-04T20:47:19.207785700Z",
          "start_time": "2024-01-04T20:47:18.513069400Z"
        },
        "id": "a06b052c"
      },
      "outputs": [],
      "source": [
        "users_frequencies[users_frequencies.index.str.lower().str.contains('amazon|kindle')]"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d547bcdc",
      "metadata": {
        "id": "d547bcdc"
      },
      "source": [
        "#### # There are still alot (8.5%) of seemingly non-unique users as Amazon Customer and Kindle Customer. Since they're verified we'll not delete those - but we'll disregard the history of the userNames \"Amazon Customer\" and \"Kindel Customers\" if they ever try to use our app for recommendations. The rest of the usernames have much lower number of ratings, and therefore are accepted as unique().   "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9dc70696",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2024-01-04T20:47:19.225463500Z",
          "start_time": "2024-01-04T20:47:18.541322500Z"
        },
        "id": "9dc70696"
      },
      "outputs": [],
      "source": [
        "assert train['userName'].isna().sum() == 0\n",
        "assert val['userName'].isna().sum() == 0\n",
        "assert test['userName'].isna().sum() == 0"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7f89fe1a",
      "metadata": {
        "id": "7f89fe1a"
      },
      "source": [
        "#### # There are no missing values for userName"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b1497ff9",
      "metadata": {
        "id": "b1497ff9"
      },
      "source": [
        "### 2. Verified - dropped after keeping only verified ratings"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c87b511f",
      "metadata": {
        "id": "c87b511f"
      },
      "source": [
        "### 3. itemName"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "35e33f50",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2024-01-04T20:47:19.243519700Z",
          "start_time": "2024-01-04T20:47:18.573691100Z"
        },
        "id": "35e33f50"
      },
      "outputs": [],
      "source": [
        "train.itemName.describe(include='all')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4434bb15",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2024-01-04T20:47:19.346004600Z",
          "start_time": "2024-01-04T20:47:18.635816900Z"
        },
        "id": "4434bb15"
      },
      "outputs": [],
      "source": [
        "train.groupby('itemName').size().describe()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1499c658",
      "metadata": {
        "id": "1499c658"
      },
      "source": [
        "#### # There are 88k \"unique\" items, with average of 3.9 ratings per image (median of 2, ratings per items is right skewed)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "badf11ec",
      "metadata": {
        "id": "badf11ec"
      },
      "source": [
        "#### # Let's drop complete duplicated rows - those are technical problems for sure, we should disregard duplicate reviews given on same item by same user in same date"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "757f6d46",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2024-01-04T20:47:19.874318200Z",
          "start_time": "2024-01-04T20:47:18.728961300Z"
        },
        "id": "757f6d46"
      },
      "outputs": [],
      "source": [
        "train.duplicated().sum()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2364ace6",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2024-01-04T20:47:21.231091100Z",
          "start_time": "2024-01-04T20:47:19.447753300Z"
        },
        "id": "2364ace6"
      },
      "outputs": [],
      "source": [
        "train = train.drop_duplicates()\n",
        "val = val.drop_duplicates()\n",
        "test = test.drop_duplicates()\n",
        "assert train.duplicated().sum() == 0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0337c233",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2024-01-04T20:47:21.824606500Z",
          "start_time": "2024-01-04T20:47:21.233240300Z"
        },
        "id": "0337c233"
      },
      "outputs": [],
      "source": [
        "probably_duplicate_ratings_col =['userName', 'description', 'image', 'brand', 'feature',\n",
        "                                 'category', 'price', 'rating', 'reviewTime', 'summary', 'reviewText',\n",
        "                                 'vote']\n",
        "pd.concat([train, y_train], axis=1).duplicated(subset=probably_duplicate_ratings_col).sum()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "965423be",
      "metadata": {
        "id": "965423be"
      },
      "source": [
        "#### # drop ratings with same exact rating by same user in same day for same item features"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cf3a3f00",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2024-01-04T20:47:23.301374400Z",
          "start_time": "2024-01-04T20:47:21.706049900Z"
        },
        "id": "cf3a3f00"
      },
      "outputs": [],
      "source": [
        "train = train.drop_duplicates(subset=probably_duplicate_ratings_col)\n",
        "assert train.duplicated(subset=probably_duplicate_ratings_col).sum() == 0\n",
        "\n",
        "val = val.drop_duplicates(subset=probably_duplicate_ratings_col)\n",
        "test = test.drop_duplicates(subset=probably_duplicate_ratings_col)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3f34580a",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2024-01-04T20:47:23.629553500Z",
          "start_time": "2024-01-04T20:47:23.226020800Z"
        },
        "id": "3f34580a"
      },
      "outputs": [],
      "source": [
        "train['itemName'].isna().sum()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3ca74af3",
      "metadata": {
        "id": "3ca74af3"
      },
      "source": [
        "#### # Drop 5 items without name - we can't recommend on it"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "72659129",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2024-01-04T20:47:23.705383Z",
          "start_time": "2024-01-04T20:47:23.254240300Z"
        },
        "id": "72659129"
      },
      "outputs": [],
      "source": [
        "train = train.dropna(subset='itemName')\n",
        "assert train['itemName'].isna().sum() == 0\n",
        "\n",
        "val = val.dropna(subset='itemName')\n",
        "test = test.dropna(subset='itemName')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cb7e51f5",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2024-01-04T20:47:23.735065300Z",
          "start_time": "2024-01-04T20:47:23.363150900Z"
        },
        "id": "cb7e51f5"
      },
      "outputs": [],
      "source": [
        "train.itemName.describe(include='all')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a17c4ecc",
      "metadata": {
        "id": "a17c4ecc"
      },
      "source": [
        "#### # There are still 88k \"unique\" items.\n",
        "#### # Examine more columns that might be identifiers for unique item: brand and price  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "eaec7925",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2024-01-04T20:47:23.979924400Z",
          "start_time": "2024-01-04T20:47:23.408389300Z"
        },
        "id": "eaec7925"
      },
      "outputs": [],
      "source": [
        "col = 'itemName'\n",
        "groupby_col = 'brand'\n",
        "get_col_unique_counts_on_groupby_col(train, col, groupby_col, sort_index=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ed28138b",
      "metadata": {
        "id": "ed28138b"
      },
      "source": [
        "#### # 55% of all items have only one brand (no competition with other brands)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b66b9f04",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2024-01-04T20:47:24.205292Z",
          "start_time": "2024-01-04T20:47:23.517213700Z"
        },
        "id": "b66b9f04"
      },
      "outputs": [],
      "source": [
        "train['reviewText'][train['reviewText'].str.lower().str.contains('price').fillna(True)]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "457cc79f",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2024-01-04T20:47:24.234523700Z",
          "start_time": "2024-01-04T20:47:23.653018900Z"
        },
        "id": "457cc79f"
      },
      "outputs": [],
      "source": [
        "21511/len(train)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2d2eeff3",
      "metadata": {
        "id": "2d2eeff3"
      },
      "source": [
        "#### # 7% of reviews talk also about prices - this should be a factor for identifying an item"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3794cfb3",
      "metadata": {
        "id": "3794cfb3"
      },
      "source": [
        "#### Create item_id from itemName, brand and price combinations"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0d70b64e",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2024-01-04T20:47:24.303996Z",
          "start_time": "2024-01-04T20:47:23.671138100Z"
        },
        "id": "0d70b64e"
      },
      "outputs": [],
      "source": [
        "train['item_id'] = train['brand'].fillna('NA') + \"_\" + train['itemName'] + \"_\" + train['price'].fillna('NA')\n",
        "train = move_cols_to_first(train, ['userName', 'item_id'])\n",
        "\n",
        "val['item_id'] = val['brand'].fillna('NA') + \"_\" + val['itemName'] + \"_\" + val['price'].fillna('NA')\n",
        "val = move_cols_to_first(val, ['userName', 'item_id'])\n",
        "test['item_id'] = test['brand'].fillna('NA') + \"_\" + test['itemName'] + \"_\" + test['price'].fillna('NA')\n",
        "test = move_cols_to_first(test, ['userName', 'item_id'])\n",
        "\n",
        "train"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ec97bd6a",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2024-01-04T20:47:24.354524900Z",
          "start_time": "2024-01-04T20:47:23.975409400Z"
        },
        "id": "ec97bd6a"
      },
      "outputs": [],
      "source": [
        "train.item_id.describe(include='all')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ce1c4796",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2024-01-04T20:47:24.558581900Z",
          "start_time": "2024-01-04T20:47:24.036556600Z"
        },
        "id": "ce1c4796"
      },
      "outputs": [],
      "source": [
        "assert train.item_id.isna().sum() == 0\n",
        "assert train.item_id.str.contains('NA_NA').sum() == 0"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a9d77a1e",
      "metadata": {
        "id": "a9d77a1e"
      },
      "source": [
        "#### # Now there are almost 89k unique items, and no NA's"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6022d44f",
      "metadata": {
        "id": "6022d44f"
      },
      "source": [
        "### 4. description"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "60b9fa58",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2024-01-04T20:47:24.606447400Z",
          "start_time": "2024-01-04T20:47:24.097943800Z"
        },
        "id": "60b9fa58"
      },
      "outputs": [],
      "source": [
        "train['description'].describe(include='all')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3fadceca",
      "metadata": {
        "id": "3fadceca"
      },
      "source": [
        "#### # Create description_n_sentences - some descriptions are made of list of different descriptions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7f15c299",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2024-01-04T20:47:27.675420600Z",
          "start_time": "2024-01-04T20:47:24.175903300Z"
        },
        "id": "7f15c299"
      },
      "outputs": [],
      "source": [
        "import ast\n",
        "\n",
        "train['description_n_sentences'] = train['description'].fillna('[]').apply(lambda x: len(ast.literal_eval(x)))\n",
        "\n",
        "val['description_n_sentences'] = val['description'].fillna('[]').apply(lambda x: len(ast.literal_eval(x)))\n",
        "test['description_n_sentences'] = test['description'].fillna('[]').apply(lambda x: len(ast.literal_eval(x)))\n",
        "\n",
        "get_col_frequencies(train, 'description_n_sentences')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "749f5552",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2024-01-04T20:47:27.787276Z",
          "start_time": "2024-01-04T20:47:27.670785500Z"
        },
        "id": "749f5552"
      },
      "outputs": [],
      "source": [
        "train['description'].isna().sum()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "64a2e2ef",
      "metadata": {
        "id": "64a2e2ef"
      },
      "source": [
        "#### # fill description NA's with NA string"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ce537e80",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2024-01-04T20:47:27.855972100Z",
          "start_time": "2024-01-04T20:47:27.701396400Z"
        },
        "id": "ce537e80"
      },
      "outputs": [],
      "source": [
        "train['description'] = train['description'].fillna(\"NA\")\n",
        "val['description'] = val['description'].fillna(\"NA\")\n",
        "test['description'] = test['description'].fillna(\"NA\")\n",
        "assert train['description'].isna().sum() == 0"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7a300ef5",
      "metadata": {
        "id": "7a300ef5"
      },
      "source": [
        "#### # Create description_len"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3b65290b",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2024-01-04T20:47:28.146981Z",
          "start_time": "2024-01-04T20:47:27.763198500Z"
        },
        "id": "3b65290b"
      },
      "outputs": [],
      "source": [
        "train['description_len'] = train['description'].str.len()\n",
        "\n",
        "val['description_len'] = val['description'].str.len()\n",
        "test['description_len'] = test['description'].str.len()\n",
        "\n",
        "get_col_frequencies(train, 'description_len')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8cd2ea6c",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2024-01-04T20:47:28.233096200Z",
          "start_time": "2024-01-04T20:47:27.841598300Z"
        },
        "id": "8cd2ea6c"
      },
      "outputs": [],
      "source": [
        "train[[col for col in train if 'description' in col]].describe(include='all')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "24d15c9b",
      "metadata": {
        "id": "24d15c9b"
      },
      "source": [
        "#### # The median description review has 1 sentence (mean=2) and 509 characters (mean=749), both are right skewed"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "17a9eef0",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2024-01-04T20:47:28.388825Z",
          "start_time": "2024-01-04T20:47:27.978890100Z"
        },
        "id": "17a9eef0"
      },
      "outputs": [],
      "source": [
        "train['description_len'].hist(bins=100, density=True)\n",
        "plt.xlim(0, 10000)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "82493dd9",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2024-01-04T20:47:28.541278400Z",
          "start_time": "2024-01-04T20:47:28.162702100Z"
        },
        "id": "82493dd9"
      },
      "outputs": [],
      "source": [
        "train['description_n_sentences'].hist(bins=100, density=True)\n",
        "plt.xlim(0, 30)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7b0ada4d",
      "metadata": {
        "id": "7b0ada4d"
      },
      "source": [
        "### 5. image"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "81310726",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2024-01-04T20:47:28.580173Z",
          "start_time": "2024-01-04T20:47:28.332076700Z"
        },
        "id": "81310726"
      },
      "outputs": [],
      "source": [
        "train['image']"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5b5478b6",
      "metadata": {
        "id": "5b5478b6"
      },
      "source": [
        "#### # Create n_images - some image are made of list of different images"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9cf00774",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2024-01-04T20:47:31.729048Z",
          "start_time": "2024-01-04T20:47:28.347288Z"
        },
        "id": "9cf00774"
      },
      "outputs": [],
      "source": [
        "train['n_images'] = train['image'].apply(lambda x: len(ast.literal_eval(x)))\n",
        "\n",
        "val['n_images'] = val['image'].apply(lambda x: len(ast.literal_eval(x)))\n",
        "test['n_images'] = test['image'].apply(lambda x: len(ast.literal_eval(x)))\n",
        "\n",
        "get_col_frequencies(train, col_name='n_images')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b0e264a0",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2024-01-04T20:47:31.923763800Z",
          "start_time": "2024-01-04T20:47:31.717081700Z"
        },
        "id": "b0e264a0"
      },
      "outputs": [],
      "source": [
        "train['n_images'].hist(bins=100, density=True)\n",
        "plt.xlim(0, 30)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "25d7002e",
      "metadata": {
        "id": "25d7002e"
      },
      "source": [
        "#### # The n_images mode is 6"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6eb61dfc",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2024-01-04T20:47:32.130942900Z",
          "start_time": "2024-01-04T20:47:31.889592800Z"
        },
        "id": "6eb61dfc"
      },
      "outputs": [],
      "source": [
        "assert train['image'].isna().sum() == 0"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "57a4970c",
      "metadata": {
        "id": "57a4970c"
      },
      "source": [
        "### 6. brand"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4e98f1fa",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2024-01-04T20:47:32.225189200Z",
          "start_time": "2024-01-04T20:47:31.919826400Z"
        },
        "id": "4e98f1fa"
      },
      "outputs": [],
      "source": [
        "train['brand'].describe()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9fb8b505",
      "metadata": {
        "id": "9fb8b505"
      },
      "source": [
        "#### # There are 21k brands! we'll group them later on by price (luxury, budget, etc.)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c93853bb",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2024-01-04T20:47:32.248334700Z",
          "start_time": "2024-01-04T20:47:31.949669600Z"
        },
        "id": "c93853bb"
      },
      "outputs": [],
      "source": [
        "get_col_frequencies(train, col_name='brand', sort_index=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "985c2d13",
      "metadata": {
        "id": "985c2d13"
      },
      "source": [
        "#### # The leading brand, KONG, is only in 1% of all ratings"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8a120e93",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2024-01-04T20:47:32.455970Z",
          "start_time": "2024-01-04T20:47:31.997124600Z"
        },
        "id": "8a120e93"
      },
      "outputs": [],
      "source": [
        "get_col_unique_counts_on_groupby_col(train, col='item_id', groupby_col='brand')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "99cb9194",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2024-01-04T20:47:32.536847500Z",
          "start_time": "2024-01-04T20:47:32.119036800Z"
        },
        "id": "99cb9194"
      },
      "outputs": [],
      "source": [
        "train['brand'].isna().sum()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5d7549c8",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2024-01-04T20:47:32.556653600Z",
          "start_time": "2024-01-04T20:47:32.134723400Z"
        },
        "id": "5d7549c8"
      },
      "outputs": [],
      "source": [
        "1560/len(train)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "18c8d47b",
      "metadata": {
        "id": "18c8d47b"
      },
      "source": [
        "#### # There are 0.5% missing brands (2180). Let's a column for brand_isna, and fill them with NA string  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f9ed1e5a",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2024-01-04T20:47:32.578160900Z",
          "start_time": "2024-01-04T20:47:32.149425400Z"
        },
        "id": "f9ed1e5a"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e91b24d2",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2024-01-04T20:47:32.592869200Z",
          "start_time": "2024-01-04T20:47:32.164980800Z"
        },
        "id": "e91b24d2"
      },
      "outputs": [],
      "source": [
        "train['brand_isna'] = train['brand'].isna()*1\n",
        "\n",
        "val['brand_isna'] = val['brand'].isna()*1\n",
        "test['brand_isna'] = test['brand'].isna()*1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5b83186e",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2024-01-04T20:47:32.612122Z",
          "start_time": "2024-01-04T20:47:32.196301300Z"
        },
        "id": "5b83186e"
      },
      "outputs": [],
      "source": [
        "train['brand_isna'].describe()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "50146cc4",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2024-01-04T20:47:32.714790500Z",
          "start_time": "2024-01-04T20:47:32.211997700Z"
        },
        "id": "50146cc4"
      },
      "outputs": [],
      "source": [
        "train['brand'] = train['brand'].fillna('NA')\n",
        "\n",
        "val['brand'] = val['brand'].fillna('NA')\n",
        "test['brand'] = test['brand'].fillna('NA')\n",
        "\n",
        "assert train['brand'].isna().sum() == 0"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9ae43a3e",
      "metadata": {
        "id": "9ae43a3e"
      },
      "source": [
        "### 7. feature"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4e139144",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2024-01-04T20:47:32.732410500Z",
          "start_time": "2024-01-04T20:47:32.258771900Z"
        },
        "id": "4e139144"
      },
      "outputs": [],
      "source": [
        "train['feature']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "48c1c2a0",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2024-01-04T20:47:32.900940Z",
          "start_time": "2024-01-04T20:47:32.272635100Z"
        },
        "id": "48c1c2a0"
      },
      "outputs": [],
      "source": [
        "assert train['feature'].isna().sum() == 0"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e759f9ca",
      "metadata": {
        "id": "e759f9ca"
      },
      "source": [
        "#### # Create n_features - some feature are made of list of different features"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "10b03e44",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2024-01-04T20:47:36.651033200Z",
          "start_time": "2024-01-04T20:47:32.305653600Z"
        },
        "id": "10b03e44"
      },
      "outputs": [],
      "source": [
        "train['n_features'] = train['feature'].apply(lambda x: len(ast.literal_eval(x)))\n",
        "\n",
        "val['n_features'] = val['feature'].apply(lambda x: len(ast.literal_eval(x)))\n",
        "test['n_features'] = test['feature'].apply(lambda x: len(ast.literal_eval(x)))\n",
        "\n",
        "get_col_frequencies(train, col_name='n_features')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "62c39ce2",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2024-01-04T20:47:36.754189400Z",
          "start_time": "2024-01-04T20:47:36.638313500Z"
        },
        "id": "62c39ce2"
      },
      "outputs": [],
      "source": [
        "#### # Create feature_len\n",
        "train['feature_len'] = train['feature'].str.len()\n",
        "\n",
        "val['feature_len'] = val['feature'].str.len()\n",
        "test['feature_len'] = test['feature'].str.len()\n",
        "\n",
        "get_col_frequencies(train, col_name='feature_len')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6987a18a",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2024-01-04T20:47:36.798718900Z",
          "start_time": "2024-01-04T20:47:36.717221200Z"
        },
        "id": "6987a18a"
      },
      "outputs": [],
      "source": [
        "train['n_features'].describe()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a0001fc3",
      "metadata": {
        "id": "a0001fc3"
      },
      "source": [
        "#### # the Median number of features per rating is 5, and the mean  5.1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "238e87fa",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2024-01-04T20:47:37.142695100Z",
          "start_time": "2024-01-04T20:47:36.731068800Z"
        },
        "id": "238e87fa"
      },
      "outputs": [],
      "source": [
        "train['n_features'].hist(bins=100, density=True)\n",
        "plt.xlim(0, 30)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ab9b059b",
      "metadata": {
        "id": "ab9b059b"
      },
      "source": [
        "### 8. category"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "267ca1ba",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2024-01-04T20:47:37.339368400Z",
          "start_time": "2024-01-04T20:47:36.918164600Z"
        },
        "id": "267ca1ba"
      },
      "outputs": [],
      "source": [
        "get_col_frequencies(train, col_name='category', sort_index=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cdb02a7f",
      "metadata": {
        "id": "cdb02a7f"
      },
      "source": [
        "#### # Most reviews (35%) are about Pet_Supplies!"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "80dbceff",
      "metadata": {
        "id": "80dbceff"
      },
      "source": [
        "#### # Move categories less than 1% categories to other categories, based on similarity to products coming up in google search of amazon <category name>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "93cd04db",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2024-01-04T20:47:37.401475500Z",
          "start_time": "2024-01-04T20:47:36.947481400Z"
        },
        "id": "93cd04db"
      },
      "outputs": [],
      "source": [
        "small_cats_to_big_cats_mapper = {'Appliances':'Industrial_and_Scientific', 'Industrial_and_Scientific':'Office_Products','AMAZON_FASHION':'Arts_Crafts_and_Sewing', 'Luxury_Beauty':'Arts_Crafts_and_Sewing', 'All_Beauty':'Arts_Crafts_and_Sewing', 'Software':'Video_Games' ,'Digital_Music':'Musical_Instruments'}\n",
        "\n",
        "train['category'] = train['category'].map(small_cats_to_big_cats_mapper).fillna(train['category'])\n",
        "train['category'] = train['category'].map(small_cats_to_big_cats_mapper).fillna(train['category'])\n",
        "\n",
        "val['category'] = val['category'].map(small_cats_to_big_cats_mapper).fillna(val['category'])\n",
        "test['category'] = test['category'].map(small_cats_to_big_cats_mapper).fillna(test['category'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d6041131",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2024-01-04T20:47:37.443063300Z",
          "start_time": "2024-01-04T20:47:37.008329200Z"
        },
        "id": "d6041131"
      },
      "outputs": [],
      "source": [
        "get_col_frequencies(train, col_name='category', sort_index=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fb1d5fa9",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2024-01-04T20:47:37.462210300Z",
          "start_time": "2024-01-04T20:47:37.039256400Z"
        },
        "id": "fb1d5fa9"
      },
      "outputs": [],
      "source": [
        "assert sum(get_col_frequencies(train, col_name='category', sort_index=False)['pct']<0.01) == 0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d22bf46d",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2024-01-04T20:47:37.477215300Z",
          "start_time": "2024-01-04T20:47:37.069818800Z"
        },
        "id": "d22bf46d"
      },
      "outputs": [],
      "source": [
        "train['category'].nunique()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4b1b6086",
      "metadata": {
        "id": "4b1b6086"
      },
      "source": [
        "#### # One-hot encode the categories"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "92fe1e08",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2024-01-04T20:47:37.590157600Z",
          "start_time": "2024-01-04T20:47:37.095137800Z"
        },
        "id": "92fe1e08"
      },
      "outputs": [],
      "source": [
        "train = pd.concat([train, pd.get_dummies(train['category'], prefix='category', drop_first=True)], axis=1)\n",
        "\n",
        "val = pd.concat([val, pd.get_dummies(val['category'], prefix='category', drop_first=True)], axis=1)\n",
        "test = pd.concat([test, pd.get_dummies(test['category'], prefix='category', drop_first=True)], axis=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "46d58469",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2024-01-04T20:47:37.661957900Z",
          "start_time": "2024-01-04T20:47:37.161370500Z"
        },
        "id": "46d58469"
      },
      "outputs": [],
      "source": [
        "train.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b3406991",
      "metadata": {
        "id": "b3406991"
      },
      "source": [
        "### 11. price"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "dfa5bb4e",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2024-01-04T20:47:37.685564700Z",
          "start_time": "2024-01-04T20:47:37.177088500Z"
        },
        "id": "dfa5bb4e"
      },
      "outputs": [],
      "source": [
        "train['price']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "63ac9b65",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2024-01-04T20:47:37.953546100Z",
          "start_time": "2024-01-04T20:47:37.191369300Z"
        },
        "id": "63ac9b65"
      },
      "outputs": [],
      "source": [
        "train['price'].dtypes"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "40940f9c",
      "metadata": {
        "id": "40940f9c"
      },
      "source": [
        "#### # change price dtype to float"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cec98ca8",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2024-01-04T20:47:38.092196400Z",
          "start_time": "2024-01-04T20:47:37.206092200Z"
        },
        "id": "cec98ca8"
      },
      "outputs": [],
      "source": [
        "train['price'] = train['price'].str.replace(\"$\", \"\")\n",
        "train['price'] = pd.to_numeric(train['price'], errors='coerce').astype(float)\n",
        "\n",
        "val['price'] = val['price'].str.replace(\"$\", \"\")\n",
        "val['price'] = pd.to_numeric(val['price'], errors='coerce').astype(float)\n",
        "test['price'] = test['price'].str.replace(\"$\", \"\")\n",
        "test['price'] = pd.to_numeric(test['price'], errors='coerce').astype(float)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "deed4436",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2024-01-04T20:47:38.132029900Z",
          "start_time": "2024-01-04T20:47:37.362431Z"
        },
        "id": "deed4436"
      },
      "outputs": [],
      "source": [
        "train['price'].describe()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c40509d4",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2024-01-04T20:47:38.175232Z",
          "start_time": "2024-01-04T20:47:37.377923900Z"
        },
        "id": "c40509d4"
      },
      "outputs": [],
      "source": [
        "train['price'].isna().sum()/len(train)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "99d673b4",
      "metadata": {
        "id": "99d673b4"
      },
      "source": [
        "#### # 17% of ratings don't contain price data\n",
        "#### # Let's mark those ratins with an indicator - prica_na, and see if we can impute them somehow (using the train data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "831955b8",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2024-01-04T20:47:38.214202300Z",
          "start_time": "2024-01-04T20:47:37.390553400Z"
        },
        "id": "831955b8"
      },
      "outputs": [],
      "source": [
        "train['price_isna'] = train['price'].isna()*1\n",
        "\n",
        "val['price_isna'] = val['price'].isna()*1\n",
        "test['price_isna'] = test['price'].isna()*1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "588f73d6",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2024-01-04T20:47:38.302247900Z",
          "start_time": "2024-01-04T20:47:37.405978500Z"
        },
        "id": "588f73d6"
      },
      "outputs": [],
      "source": [
        "train['brand_itemName'] = train['brand'] + \"_\" + train['itemName']\n",
        "\n",
        "val['brand_itemName'] = val['brand'] + \"_\" + val['itemName']\n",
        "test['brand_itemName'] = test['brand'] + \"_\" + test['itemName']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "dd7c552f",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2024-01-04T20:47:39.032331400Z",
          "start_time": "2024-01-04T20:47:37.469559400Z"
        },
        "id": "dd7c552f"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Assuming train has columns 'item_id', 'price', and 'reviewTime' where 'reviewTime' is a date\n",
        "\n",
        "# Convert 'reviewTime' to datetime\n",
        "train['reviewTime'] = pd.to_datetime(train['reviewTime'])\n",
        "\n",
        "# Filter out rows where 'price' is missing\n",
        "filtered_train = train.dropna(subset=['price'])\n",
        "\n",
        "# Group by 'item_id' and 'reviewTime', then calculate the mean price\n",
        "grouped_train = filtered_train.groupby(['brand_itemName', 'reviewTime'])['price'].mean().reset_index()\n",
        "\n",
        "# Plotting\n",
        "for item in grouped_train['brand_itemName'].unique()[:100]:\n",
        "    item_train = grouped_train[grouped_train['brand_itemName'] == item]\n",
        "    plt.plot(item_train['reviewTime'], item_train['price'], label=item)\n",
        "\n",
        "plt.xlabel('Review Time')\n",
        "plt.ylabel('Price')\n",
        "plt.title('Price Change Over Time for Each Item')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c43c86c6",
      "metadata": {
        "id": "c43c86c6"
      },
      "source": [
        "#### # It seems prices don't change over date, so we can safetly use the train averages of all periods to fill missing prices"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1fa42766",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2024-01-04T20:47:39.062405300Z",
          "start_time": "2024-01-04T20:47:38.500430100Z"
        },
        "id": "1fa42766"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Calculate the average price for each item\n",
        "average_prices_dict = train.dropna(subset='price').groupby('brand_itemName')['price'].mean().to_dict()\n",
        "\n",
        "# Fill missing prices using map and fillna\n",
        "train['price'] = train['price'].fillna(train['brand_itemName'].map(average_prices_dict))\n",
        "val['price'] = val['price'].fillna(val['brand_itemName'].map(average_prices_dict))\n",
        "test['price'] = test['price'].fillna(test['brand_itemName'].map(average_prices_dict))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "66a6c982",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2024-01-04T20:47:39.076954700Z",
          "start_time": "2024-01-04T20:47:38.653678Z"
        },
        "id": "66a6c982"
      },
      "outputs": [],
      "source": [
        "train['price'].isna().sum()/len(train)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "43b105f6",
      "metadata": {
        "id": "43b105f6"
      },
      "source": [
        "#### # still alot of NA's. let's see if we can fill those with means of ['category', 'brand'] pricees"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "16a149ac",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2024-01-04T20:47:39.351733600Z",
          "start_time": "2024-01-04T20:47:38.668912800Z"
        },
        "id": "16a149ac"
      },
      "outputs": [],
      "source": [
        "train_group_cat_brand_price = train.groupby(['category', 'brand'])['price'].agg(['mean', 'std'])\n",
        "train_group_cat_brand_price"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8b5c1609",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2024-01-04T20:47:39.409489300Z",
          "start_time": "2024-01-04T20:47:38.715999300Z"
        },
        "id": "8b5c1609"
      },
      "outputs": [],
      "source": [
        "train_group_cat_brand_price['mean'].isna().sum()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3b9e34fb",
      "metadata": {
        "id": "3b9e34fb"
      },
      "source": [
        "#### # there are still some NA's for the category+brand price means, will fill them with the category means:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d362fc9c",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2024-01-04T20:47:39.444558600Z",
          "start_time": "2024-01-04T20:47:38.731427700Z"
        },
        "id": "d362fc9c"
      },
      "outputs": [],
      "source": [
        "category_price_means = train.groupby(['category']).price.mean().to_dict()\n",
        "\n",
        "# Extract category level from the multi-index of train_group_cat_brand_price\n",
        "categories = train_group_cat_brand_price.index.get_level_values('category')\n",
        "\n",
        "# Map the category means to fill missing mean prices\n",
        "train_group_cat_brand_price['mean'] = train_group_cat_brand_price['mean'].fillna(pd.Series(categories, index=train_group_cat_brand_price.index).map(category_price_means))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "192cc574",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2024-01-04T20:47:39.466980700Z",
          "start_time": "2024-01-04T20:47:38.761159300Z"
        },
        "id": "192cc574"
      },
      "outputs": [],
      "source": [
        "assert train_group_cat_brand_price['mean'].isna().sum() == 0"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b7391b63",
      "metadata": {
        "id": "b7391b63"
      },
      "source": [
        "#### # Now examine train_group_cat_brand_price coffiecient of variations to see if they make a good approximation of the prices"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7261cf56",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2024-01-04T20:47:39.492408900Z",
          "start_time": "2024-01-04T20:47:38.774900Z"
        },
        "id": "7261cf56"
      },
      "outputs": [],
      "source": [
        "train_group_cat_brand_price['CV'] = train_group_cat_brand_price['mean'] / train_group_cat_brand_price['std']\n",
        "train_group_cat_brand_price"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "99707d70",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2024-01-04T20:47:39.507136100Z",
          "start_time": "2024-01-04T20:47:38.790804700Z"
        },
        "id": "99707d70"
      },
      "outputs": [],
      "source": [
        "train_group_cat_brand_price['CV'].describe().round(2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "051b253b",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2024-01-04T20:47:39.531136400Z",
          "start_time": "2024-01-04T20:47:38.806620800Z"
        },
        "id": "051b253b"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "\n",
        "\n",
        "cv_values = train_group_cat_brand_price['CV']\n",
        "# Replace inf values with NaN and then drop them\n",
        "cv_values = np.array(cv_values)  # Ensure cv_values is a NumPy array\n",
        "cv_values[np.isinf(cv_values)] = np.nan\n",
        "cv_values_cleaned = cv_values[~np.isnan(cv_values)]\n",
        "\n",
        "plt.figure(figsize=(10, 6))\n",
        "sns.boxplot(cv_values)\n",
        "plt.title('Box Plot of Coefficient of Variation (CV)')\n",
        "plt.xlabel('CV')\n",
        "plt.ylim(0, 10)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "986fcec9",
      "metadata": {
        "id": "986fcec9"
      },
      "source": [
        "#### It looks like Coefficients of Variation of the prices of the category brands groups is high enough - most prices in groups are close to the mean price.\n",
        "#### # Fill the missing prices with those prices"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a09e13ec",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2024-01-04T20:47:40.162091200Z",
          "start_time": "2024-01-04T20:47:38.899912800Z"
        },
        "id": "a09e13ec"
      },
      "outputs": [],
      "source": [
        "# Convert the group means to a dictionary with a MultiIndex\n",
        "mean_price_dict = train_group_cat_brand_price['mean'].to_dict()\n",
        "\n",
        "# Create a MultiIndex in your original DataFrame for mapping\n",
        "train['category_brand'] = pd.MultiIndex.from_frame(train[['category', 'brand']])\n",
        "\n",
        "val['category_brand'] = pd.MultiIndex.from_frame(val[['category', 'brand']])\n",
        "test['category_brand'] = pd.MultiIndex.from_frame(test[['category', 'brand']])\n",
        "\n",
        "# Map the means and fill in missing values\n",
        "train['price'] = train['price'].fillna(train['category_brand'].map(mean_price_dict))\n",
        "\n",
        "val['price'] = val['price'].fillna(val['category_brand'].map(mean_price_dict))\n",
        "test['price'] = test['price'].fillna(test['category_brand'].map(mean_price_dict))\n",
        "\n",
        "# Optionally, you can drop the 'category_brand' column if it's no longer needed\n",
        "train.drop(['category_brand','brand_itemName'], axis=1, inplace=True, errors='ignore')\n",
        "\n",
        "val.drop(['category_brand','brand_itemName'], axis=1, inplace=True, errors='ignore')\n",
        "test.drop(['category_brand','brand_itemName'], axis=1, inplace=True, errors='ignore')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e737bdbc",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2024-01-04T20:47:40.237800400Z",
          "start_time": "2024-01-04T20:47:39.497959800Z"
        },
        "id": "e737bdbc"
      },
      "outputs": [],
      "source": [
        "assert train['price'].isna().sum()/len(train) == 0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8a8dd2fc",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2024-01-04T20:47:40.267648600Z",
          "start_time": "2024-01-04T20:47:39.511556300Z"
        },
        "id": "8a8dd2fc"
      },
      "outputs": [],
      "source": [
        "val['price'].isna().sum()/len(val)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ffdc9984",
      "metadata": {
        "id": "ffdc9984"
      },
      "source": [
        "#### # Fill the reminaing val and test NA's with train's category_price_means"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2f85cca3",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2024-01-04T20:47:40.322951900Z",
          "start_time": "2024-01-04T20:47:39.526309100Z"
        },
        "id": "2f85cca3"
      },
      "outputs": [],
      "source": [
        "val['price'] = val['price'].fillna(val['category'].map(category_price_means))\n",
        "test['price'] = test['price'].fillna(test['category'].map(category_price_means))\n",
        "assert val['price'].isna().sum()/len(val) == 0\n",
        "assert test['price'].isna().sum()/len(test) == 0"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "dfaf4d4c",
      "metadata": {
        "id": "dfaf4d4c"
      },
      "source": [
        "#### # Now, let's Group brands to brand_price_group"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3da1f0e7",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2024-01-04T20:47:40.340905600Z",
          "start_time": "2024-01-04T20:47:39.541530200Z"
        },
        "id": "3da1f0e7"
      },
      "outputs": [],
      "source": [
        "brand_price_group_mapper = pd.qcut(train.groupby('brand')['price'].mean(), 10).rename('brand_price_group').to_dict()\n",
        "train['brand_price_group'] = train['brand'].map(brand_price_group_mapper)\n",
        "\n",
        "val['brand_price_group'] = val['brand'].map(brand_price_group_mapper)\n",
        "test['brand_price_group'] = test['brand'].map(brand_price_group_mapper)\n",
        "\n",
        "train['brand_price_group']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4a90be12",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2024-01-04T20:47:40.362157500Z",
          "start_time": "2024-01-04T20:47:39.650416500Z"
        },
        "id": "4a90be12"
      },
      "outputs": [],
      "source": [
        "assert train['brand_price_group'].isna().sum() == 0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5b7f5edb",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2024-01-04T20:47:40.383044800Z",
          "start_time": "2024-01-04T20:47:39.666961700Z"
        },
        "id": "5b7f5edb"
      },
      "outputs": [],
      "source": [
        "val['brand_price_group'].isna().sum(), test['brand_price_group'].isna().sum()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8f7a1745",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2024-01-04T20:47:40.459726800Z",
          "start_time": "2024-01-04T20:47:39.679462900Z"
        },
        "id": "8f7a1745"
      },
      "outputs": [],
      "source": [
        "train_brand_price_mode = train['brand_price_group'].mode()[0]\n",
        "train_brand_price_mode"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b757f509",
      "metadata": {
        "id": "b757f509"
      },
      "source": [
        "#### # fillna's in val and test (brand that don't exist in train) with train brand_price_group mode"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6a2e9e0e",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2024-01-04T20:47:40.502468500Z",
          "start_time": "2024-01-04T20:47:39.804138600Z"
        },
        "id": "6a2e9e0e"
      },
      "outputs": [],
      "source": [
        "val['brand_price_group'] = val['brand_price_group'].fillna(train_brand_price_mode)\n",
        "test['brand_price_group'] = test['brand_price_group'].fillna(train_brand_price_mode)\n",
        "\n",
        "assert val['brand_price_group'].isna().sum() == 0\n",
        "assert test['brand_price_group'].isna().sum() == 0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2e30da02",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2024-01-04T20:47:42.756378600Z",
          "start_time": "2024-01-04T20:47:39.818863600Z"
        },
        "id": "2e30da02"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=(12,8))\n",
        "sns.countplot(x='brand_price_group', data=train.sort_values(by='brand_price_group'))\n",
        "\n",
        "plt.tight_layout()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "80c41ca5",
      "metadata": {
        "id": "80c41ca5"
      },
      "source": [
        "#### # One-hot encode the 10 brand_price_group"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a8073596",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2024-01-04T20:47:43.068426600Z",
          "start_time": "2024-01-04T20:47:42.736146900Z"
        },
        "id": "a8073596"
      },
      "outputs": [],
      "source": [
        "train = pd.concat([train, pd.get_dummies(train['brand_price_group'], prefix='brand_price', drop_first=True)], axis=1)\n",
        "\n",
        "val = pd.concat([val, pd.get_dummies(val['brand_price_group'], prefix='brand_price', drop_first=True)], axis=1)\n",
        "test = pd.concat([test, pd.get_dummies(test['brand_price_group'], prefix='brand_price', drop_first=True)], axis=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2b3e9dba",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2024-01-04T20:47:43.179881200Z",
          "start_time": "2024-01-04T20:47:43.013640600Z"
        },
        "id": "2b3e9dba"
      },
      "outputs": [],
      "source": [
        "train"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "70fbb954",
      "metadata": {
        "id": "70fbb954"
      },
      "source": [
        "### 12. reviewTime"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "42635201",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2024-01-04T20:47:43.256046Z",
          "start_time": "2024-01-04T20:47:43.044585Z"
        },
        "id": "42635201"
      },
      "outputs": [],
      "source": [
        "train['reviewTime'] = pd.to_datetime(train['reviewTime'])\n",
        "\n",
        "val['reviewTime'] = pd.to_datetime(val['reviewTime'])\n",
        "test['reviewTime'] = pd.to_datetime(test['reviewTime'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c6ad7451",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2024-01-04T20:47:43.283314Z",
          "start_time": "2024-01-04T20:47:43.075076700Z"
        },
        "id": "c6ad7451"
      },
      "outputs": [],
      "source": [
        "train['reviewTime'].describe()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6ebe7f4c",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2024-01-04T20:47:43.322178Z",
          "start_time": "2024-01-04T20:47:43.088738200Z"
        },
        "id": "6ebe7f4c"
      },
      "outputs": [],
      "source": [
        "print(train['reviewTime'].min(), train['reviewTime'].max(),\n",
        "\n",
        "val['reviewTime'].min(), val['reviewTime'].max(),\n",
        "test['reviewTime'].min(), test['reviewTime'].max())"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b6f97d59",
      "metadata": {
        "id": "b6f97d59"
      },
      "source": [
        "#### # There are  277 days in reviewTime, from Jan 2018 to Cct 10.\n",
        "#### # We saw the prices don't change in different dates.\n",
        "#### # Not sure we'll do something with those dates - we'll recommend based on all historical ratings, regardless of date"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8aced67c",
      "metadata": {
        "id": "8aced67c"
      },
      "source": [
        "### 13. summary"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d6450eaa",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2024-01-04T20:47:43.441630100Z",
          "start_time": "2024-01-04T20:47:43.105251100Z"
        },
        "id": "d6450eaa"
      },
      "outputs": [],
      "source": [
        "train['summary']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "29b5b1a2",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2024-01-04T20:47:43.719521600Z",
          "start_time": "2024-01-04T20:47:43.119969300Z"
        },
        "id": "29b5b1a2"
      },
      "outputs": [],
      "source": [
        "train['summary'].isna().sum()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "12233c84",
      "metadata": {
        "id": "12233c84"
      },
      "source": [
        "#### # add a column for summary_isna and fill NA's with ''"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b73de752",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2024-01-04T20:47:43.767477300Z",
          "start_time": "2024-01-04T20:47:43.151786200Z"
        },
        "id": "b73de752"
      },
      "outputs": [],
      "source": [
        "train['summary_isna'] = train['summary'].isna()*1\n",
        "\n",
        "val['summary_isna'] = val['summary'].isna()*1\n",
        "test['summary_isna'] = test['summary'].isna()*1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1b795481",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2024-01-04T20:47:43.836927300Z",
          "start_time": "2024-01-04T20:47:43.182614800Z"
        },
        "id": "1b795481"
      },
      "outputs": [],
      "source": [
        "train['summary'] = train['summary'].fillna(\"\")\n",
        "\n",
        "val['summary'] = val['summary'].fillna(\"\")\n",
        "test['summary'] = test['summary'].fillna(\"\")\n",
        "assert train['summary'].isna().sum() == 0"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "eab1fdf5",
      "metadata": {
        "id": "eab1fdf5"
      },
      "source": [
        "#### # Create numeric features for the summary - summary_len, summary_n_words - even though we might not use this data in the end"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7429f110",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2024-01-04T20:47:43.983980400Z",
          "start_time": "2024-01-04T20:47:43.226112300Z"
        },
        "id": "7429f110"
      },
      "outputs": [],
      "source": [
        "train['summary_len'] = train['summary'].str.len()\n",
        "\n",
        "val['summary_len'] = val['summary'].str.len()\n",
        "test['summary_len'] = test['summary'].str.len()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f0011111",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2024-01-04T20:47:44.472291500Z",
          "start_time": "2024-01-04T20:47:43.304630800Z"
        },
        "id": "f0011111"
      },
      "outputs": [],
      "source": [
        "train['summary_n_words'] = train['summary'].str.split().str.len()\n",
        "\n",
        "val['summary_n_words'] = val['summary'].str.split().str.len()\n",
        "test['summary_n_words'] = test['summary'].str.split().str.len()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4662f705",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2024-01-04T20:47:44.498094400Z",
          "start_time": "2024-01-04T20:47:43.885009Z"
        },
        "id": "4662f705"
      },
      "outputs": [],
      "source": [
        "train[[col for col in train if 'summary' in col]].describe()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1b769b8d",
      "metadata": {
        "id": "1b769b8d"
      },
      "source": [
        "#### # 2% of ratings don't have a summary, the median summary has 12 characters and 2 words - most probably that's just \"X stars\""
      ]
    },
    {
      "cell_type": "markdown",
      "id": "40999c9a",
      "metadata": {
        "id": "40999c9a"
      },
      "source": [
        "### 14. reviewText"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8b62a83a",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2024-01-04T20:47:44.532344600Z",
          "start_time": "2024-01-04T20:47:43.976427Z"
        },
        "id": "8b62a83a"
      },
      "outputs": [],
      "source": [
        "train['reviewText']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b46f20d5",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2024-01-04T20:47:44.558656600Z",
          "start_time": "2024-01-04T20:47:43.990617700Z"
        },
        "id": "b46f20d5"
      },
      "outputs": [],
      "source": [
        "train['reviewText'].describe()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "33794701",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2024-01-04T20:47:44.589887300Z",
          "start_time": "2024-01-04T20:47:44.067705Z"
        },
        "id": "33794701"
      },
      "outputs": [],
      "source": [
        "train['reviewText'].isna().sum()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "efc81190",
      "metadata": {
        "id": "efc81190"
      },
      "source": [
        "#### # add a column for reviewText_isna and fill NA's with ''"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a3b675b8",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2024-01-04T20:47:44.604831300Z",
          "start_time": "2024-01-04T20:47:44.099062700Z"
        },
        "id": "a3b675b8"
      },
      "outputs": [],
      "source": [
        "train['reviewText_isna'] = train['reviewText'].isna()*1\n",
        "\n",
        "val['reviewText_isna'] = val['reviewText'].isna()*1\n",
        "test['reviewText_isna'] = test['reviewText'].isna()*1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d63377d2",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2024-01-04T20:47:44.630199300Z",
          "start_time": "2024-01-04T20:47:44.146074300Z"
        },
        "id": "d63377d2"
      },
      "outputs": [],
      "source": [
        "train['reviewText'] = train['reviewText'].fillna(\"\")\n",
        "\n",
        "val['reviewText'] = val['reviewText'].fillna(\"\")\n",
        "test['reviewText'] = test['reviewText'].fillna(\"\")\n",
        "assert train['reviewText'].isna().sum() == 0"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6f3f023b",
      "metadata": {
        "id": "6f3f023b"
      },
      "source": [
        "#### # Create numeric features for the summary - summary_len, summary_n_words - even though we might not use this data in the end"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6d635447",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2024-01-04T20:47:44.799325Z",
          "start_time": "2024-01-04T20:47:44.222255800Z"
        },
        "id": "6d635447"
      },
      "outputs": [],
      "source": [
        "train['reviewText_len'] = train['reviewText'].str.len()\n",
        "\n",
        "val['reviewText_len'] = val['reviewText'].str.len()\n",
        "test['reviewText_len'] = test['reviewText'].str.len()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b2178c82",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2024-01-04T20:47:45.321381Z",
          "start_time": "2024-01-04T20:47:44.299904Z"
        },
        "id": "b2178c82"
      },
      "outputs": [],
      "source": [
        "train['reviewText_n_words'] = train['reviewText'].str.split().str.len()\n",
        "\n",
        "val['reviewText_n_words'] = val['reviewText'].str.split().str.len()\n",
        "test['reviewText_n_words'] = test['reviewText'].str.split().str.len()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "77314ee7",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2024-01-04T20:47:45.366289700Z",
          "start_time": "2024-01-04T20:47:44.883442300Z"
        },
        "id": "77314ee7"
      },
      "outputs": [],
      "source": [
        "train[[col for col in train if 'reviewText' in col]].describe()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "94ecbd48",
      "metadata": {
        "id": "94ecbd48"
      },
      "source": [
        "#### # 3% of reviewText are missing, and the median reviewText have 70 characters in 13 words"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "68ed5ab2",
      "metadata": {
        "id": "68ed5ab2"
      },
      "source": [
        "### 15. vote"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1c916fb3",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2024-01-04T20:47:45.380312600Z",
          "start_time": "2024-01-04T20:47:44.974184700Z"
        },
        "id": "1c916fb3"
      },
      "outputs": [],
      "source": [
        "df['vote'].describe()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b86a8166",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2024-01-04T20:47:45.402556200Z",
          "start_time": "2024-01-04T20:47:44.988372800Z"
        },
        "id": "b86a8166"
      },
      "outputs": [],
      "source": [
        "df['vote'].isna().sum()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "61842a58",
      "metadata": {
        "id": "61842a58"
      },
      "source": [
        "#### # votes is a different feature that the other ones - we might use it as weights in the model"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f96dec8d",
      "metadata": {
        "id": "f96dec8d"
      },
      "source": [
        "## Handle Outliers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cebd1a6e",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2024-01-04T20:47:45.812446100Z",
          "start_time": "2024-01-04T20:47:45.004311200Z"
        },
        "id": "cebd1a6e"
      },
      "outputs": [],
      "source": [
        "train_statistics = train.drop(columns=target).describe(include='all').T\n",
        "train_statistics"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b51386d1",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2024-01-04T20:47:45.853111800Z",
          "start_time": "2024-01-04T20:47:45.650163100Z"
        },
        "id": "b51386d1"
      },
      "outputs": [],
      "source": [
        "orig_cols"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c4a54d01",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2024-01-04T20:47:45.965304500Z",
          "start_time": "2024-01-04T20:47:45.667755700Z"
        },
        "id": "c4a54d01"
      },
      "outputs": [],
      "source": [
        "numeric_cols_no_target = [col for col in train.describe().columns if target not in col if col in train.columns]\n",
        "numeric_cols_no_target"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "dd3238d8",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2024-01-04T20:47:47.196030600Z",
          "start_time": "2024-01-04T20:47:45.792636600Z"
        },
        "id": "dd3238d8"
      },
      "outputs": [],
      "source": [
        "\n",
        "# Add outlier column indicator, having 1 for outlier rows\n",
        "train_numeric_features = numeric_cols_no_target  # When none, assume train dataset and find all relevent columns\n",
        "train_n_uniques = train[numeric_cols_no_target].nunique()\n",
        "train_numeric_features = train_n_uniques[train_n_uniques>2].index.tolist()\n",
        "train, train_outiler_cols = add_outlier_indicators_on_features(train, train_statistics,\n",
        "                                                               X_train_numeric_features=train_numeric_features,\n",
        "                                                                 outlier_col_suffix=outlier_col_suffix)\n",
        "\n",
        "# if outliers exist, update outlier statistics to train_statistics\n",
        "if len(train_outiler_cols) > 0:\n",
        "    train_statistics = add_new_features_statistics_to_train_statistics(train, train_statistics, train_outiler_cols)\n",
        "\n",
        "# Apply outlier indicators on validation and test\n",
        "\n",
        "# get train outlier columns\n",
        "train_outiler_cols = get_train_features_with_suffix(train_statistics, the_suffix=outlier_col_suffix)\n",
        "# if outliers exist in train, add outlier indicators to val and test in those specific features\n",
        "if len(train_outiler_cols) > 0:\n",
        "    add_outlier_indicators_on_features_fn = partial(add_outlier_indicators_on_features,\n",
        "                                                    the_train_statistics=train_statistics,\n",
        "                                                    X_train_numeric_features=train_outiler_cols,\n",
        "                                                    outlier_col_suffix=outlier_col_suffix)\n",
        "    val, _ = add_outlier_indicators_on_features_fn(val)\n",
        "    test, _ = add_outlier_indicators_on_features_fn(test)\n",
        "\n",
        "    # Validate outliers detection: Test if train outlier statistics are different from val outlier statistics\n",
        "    remove_suffix = False\n",
        "    train_outlier_cols = get_train_features_with_suffix(train_statistics, the_suffix=outlier_col_suffix,\n",
        "                                                        remove_suffix=remove_suffix)\n",
        "    remove_suffix = True\n",
        "    train_orig_outlier_cols = get_train_features_with_suffix(train_statistics, the_suffix=outlier_col_suffix,\n",
        "                                                             remove_suffix=remove_suffix)\n",
        "    train_outliers = train.loc[(train[train_outlier_cols] == 1).any(axis=1), train_orig_outlier_cols]\n",
        "    val_outliers = val.loc[(val[train_outlier_cols] == 1).any(axis=1), train_orig_outlier_cols]\n",
        "    print(f\"\\n# The train outliers:\\n {train_outliers}\")\n",
        "    trains_dict_to_test = {'val_outliers': val_outliers}\n",
        "    # train_val_outlier_means_test = test_if_features_statistically_different(train_outliers, trains_dict_to_test,\n",
        "    #                                                                         alpha=alpha)\n",
        "    # print('\\n# Test if train and validation outliers means are statisically not different:\\n',\n",
        "    #       train_val_outlier_means_test)\n",
        "\n",
        "# Impute outliers features\n",
        "\n",
        "train_statistics = add_winsorization_values_to_train_statistics(train.drop(columns=target), train_statistics)\n",
        "train = pd.concat([winsorize_outliers(train.drop(columns=target), train_statistics), train[target]], axis=1)\n",
        "val = pd.concat([winsorize_outliers(val.drop(columns=target), train_statistics), val[target]], axis=1)\n",
        "test = pd.concat([winsorize_outliers(test.drop(columns=target), train_statistics), test[target]], axis=1)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "dd487572",
      "metadata": {
        "id": "dd487572"
      },
      "source": [
        "# Add Collaborative filtering features"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6122eb04",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2024-01-04T20:47:47.504874Z",
          "start_time": "2024-01-04T20:47:47.184036800Z"
        },
        "id": "6122eb04"
      },
      "outputs": [],
      "source": [
        "import gc\n",
        "gc.collect()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2b67c920",
      "metadata": {
        "id": "2b67c920"
      },
      "source": [
        "#### # The following lines will take a few minutes to run..."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3c961996",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2024-01-04T20:47:56.250743300Z",
          "start_time": "2024-01-04T20:47:47.507032500Z"
        },
        "id": "3c961996"
      },
      "outputs": [],
      "source": [
        "# Create a user-item matrix\n",
        "user_item_matrix = train.pivot_table(index='userName', columns='item_id', values='rating')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4101cb26",
      "metadata": {
        "id": "4101cb26"
      },
      "source": [
        "## User-Based Collaborative Filtering - how similar users rated an item"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2ac1281c",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2024-01-04T20:48:15.983009100Z",
          "start_time": "2024-01-04T20:47:56.228965300Z"
        },
        "id": "2ac1281c"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "\n",
        "# Compute cosine similarity between users\n",
        "user_similarity = cosine_similarity(user_item_matrix.fillna(0))\n",
        "\n",
        "# Convert to DataFrame\n",
        "user_similarity_df = pd.DataFrame(user_similarity, index=user_item_matrix.index, columns=user_item_matrix.index)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cbe631ce",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2024-01-04T20:48:16.025179700Z",
          "start_time": "2024-01-04T20:48:15.984673400Z"
        },
        "id": "cbe631ce"
      },
      "outputs": [],
      "source": [
        "user_similarity_df.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f86da0d6",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2024-01-04T20:48:33.295606300Z",
          "start_time": "2024-01-04T20:48:16.000462400Z"
        },
        "id": "f86da0d6"
      },
      "outputs": [],
      "source": [
        "def create_similar_users_dict(user_similarity_df, top_n=5):\n",
        "    similar_users_dict = {}\n",
        "    for user in user_similarity_df.index:\n",
        "        # Get top N similar users; skip the first one as it will be the user itself\n",
        "        top_similar = user_similarity_df[user].sort_values(ascending=False)[1:top_n+1]\n",
        "        similar_users_dict[user] = list(zip(top_similar.index, top_similar.values))\n",
        "    return similar_users_dict\n",
        "\n",
        "# Assuming user_similarity_df is your user-user similarity DataFrame\n",
        "similar_users_dict = create_similar_users_dict(user_similarity_df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e1fca56a",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2024-01-04T20:48:33.348312400Z",
          "start_time": "2024-01-04T20:48:33.297705500Z"
        },
        "id": "e1fca56a"
      },
      "outputs": [],
      "source": [
        "similar_users_dict.keys()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c40e7053",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2024-01-04T20:48:33.476748200Z",
          "start_time": "2024-01-04T20:48:33.311882200Z"
        },
        "id": "c40e7053"
      },
      "outputs": [],
      "source": [
        "similar_users_dict[' Boo']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "71bad8b7",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2024-01-04T20:48:33.605381800Z",
          "start_time": "2024-01-04T20:48:33.327030200Z"
        },
        "id": "71bad8b7"
      },
      "outputs": [],
      "source": [
        "train[train['userName'].isin([' Boo','J. V. Robinson'])].sort_values('item_id')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a280c789",
      "metadata": {
        "id": "a280c789"
      },
      "source": [
        "#### # Test similarity matrix - they're indeed similair - both in item rated and in their ratings!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c22ffeca",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2024-01-04T20:48:33.656476500Z",
          "start_time": "2024-01-04T20:48:33.358348200Z"
        },
        "id": "c22ffeca"
      },
      "outputs": [],
      "source": [
        "train[train['userName'].isin([' Boo','kim tindell'])].sort_values('item_id').sort_values('item_id')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8050ffd8",
      "metadata": {
        "id": "8050ffd8"
      },
      "source": [
        "#### # They're less similar"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "bd2485e2",
      "metadata": {
        "id": "bd2485e2"
      },
      "source": [
        "## Create features based on statistics on similar users: this will take about 30 minutes, depending on your hardware..."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9b007b2e",
      "metadata": {
        "id": "9b007b2e"
      },
      "source": [
        "#### # The following box will take a few minutes to run..."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5e74632e",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2024-01-04T20:48:37.390098200Z",
          "start_time": "2024-01-04T20:48:33.411051Z"
        },
        "id": "5e74632e"
      },
      "outputs": [],
      "source": [
        "from tqdm import tqdm\n",
        "import gc\n",
        "\n",
        "def similar_users_weighted_average_features_for_item(user_id, item_id, similar_users_dict, train_df, n_similar_users=5, features=None, default_val=0):\n",
        "    if features is None:\n",
        "        features = ['rating', 'description_len', 'n_images', 'feature_len', 'price', 'summary_len', 'reviewText_len']\n",
        "    # Check if the user_id exists in the similar_users_dict\n",
        "    if user_id not in similar_users_dict:\n",
        "        # Create a Series with default values and correct index names\n",
        "        default_values = [default_val] * len(features)\n",
        "        default_series = pd.Series(default_values, index=[f'sim_{n_similar_users}_users_{feature}' for feature in features])\n",
        "        return default_series\n",
        "\n",
        "    # Filter for the specific item\n",
        "    train_df_filtered  = train_df[train_df['item_id'] == item_id]\n",
        "\n",
        "    # Get top N similar users for the given user\n",
        "    top_similar_users = similar_users_dict[user_id][:n_similar_users]\n",
        "\n",
        "    # Create a DataFrame from the similar users list\n",
        "    similar_users_df = pd.DataFrame(top_similar_users, columns=['userName', 'similarity_score'])\n",
        "\n",
        "    # Merge with the ratings DataFrame\n",
        "    item_features = pd.merge(similar_users_df, train_df_filtered , on='userName')\n",
        "\n",
        "    # Calculate weighted averages for all features\n",
        "    weighted_avgs = {}\n",
        "    for feature in features:\n",
        "        if not item_features.empty:\n",
        "            weighted_avg = (item_features[feature].multiply(item_features['similarity_score'], axis=0)).sum() / item_features['similarity_score'].sum()\n",
        "        else:\n",
        "            weighted_avg = 0  # or a default value, depending on your use case\n",
        "        weighted_avgs[feature] = weighted_avg\n",
        "\n",
        "    # Convert the result to a DataFrame\n",
        "    #result_df = pd.DataFrame([weighted_avgs]).add_suffix(f'sim_{n_similar_users}_users_')\n",
        "    result_series = pd.Series(weighted_avgs.values(), index=[f'sim_{n_similar_users}_users_{feature}' for feature in features])\n",
        "\n",
        "    return result_series\n",
        "\n",
        "def process_in_chunks(the_df, similar_users_dict, train_df, features, chunk_size=1000, n_similar_users=5):\n",
        "    # Create chunks of the DataFrame\n",
        "    chunks = (the_df.iloc[i:i + chunk_size] for i in range(0, the_df.shape[0], chunk_size))\n",
        "\n",
        "    # Initialize an empty list to store processed chunks\n",
        "    processed_chunks = []\n",
        "\n",
        "    # Iterate through the chunks\n",
        "    for chunk in tqdm(chunks, total=the_df.shape[0] // chunk_size):\n",
        "        # Apply the function to calculate weighted averages for the features\n",
        "        weighted_avg_features = chunk.apply(lambda row: similar_users_weighted_average_features_for_item(\n",
        "            user_id=row['userName'],\n",
        "            item_id=row['item_id'],\n",
        "            similar_users_dict=similar_users_dict,\n",
        "            train_df=train_df,\n",
        "            features=features,\n",
        "            n_similar_users=n_similar_users\n",
        "        ), axis=1)\n",
        "        # Concatenate the result to the original chunk\n",
        "        chunk = pd.concat([chunk, weighted_avg_features], axis=1)\n",
        "        # Append the processed chunk to the list\n",
        "        processed_chunks.append(chunk)\n",
        "\n",
        "        # After processing each chunk\n",
        "        del chunk\n",
        "        gc.collect()\n",
        "\n",
        "    # Combine the processed chunks back into a single DataFrame\n",
        "    return pd.concat(processed_chunks)\n",
        "\n",
        "# Define the list of features you want to calculate weighted averages for\n",
        "features = ['rating', 'description_len', 'n_images', 'feature_len', 'price', 'summary_len', 'reviewText_len']\n",
        "\n",
        "\n",
        "IMPORT_DFS = True\n",
        "SAVE_DFS = False\n",
        "# Process each dataset\n",
        "chunk_size = 500\n",
        "\n",
        "train_processed = pd.read_csv(\"train_processed.csv\") if IMPORT_DFS else process_in_chunks(train, similar_users_dict, train, features, chunk_size=chunk_size)\n",
        "train_processed.to_csv(\"train_processed.csv\", index=False) if SAVE_DFS else \"\"\n",
        "val_processed = pd.read_csv(\"val_processed.csv\") if IMPORT_DFS else process_in_chunks(val, similar_users_dict, train, features, chunk_size=chunk_size)\n",
        "val_processed.to_csv(\"val_processed.csv\", index=False) if SAVE_DFS else \"\"\n",
        "test_processed = pd.read_csv(\"test_processed.csv\") if IMPORT_DFS else process_in_chunks(test, similar_users_dict, train, features, chunk_size=chunk_size)\n",
        "test_processed.to_csv(\"test_processed.csv\", index=False) if SAVE_DFS else \"\""
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a722f852",
      "metadata": {
        "id": "a722f852"
      },
      "source": [
        "## Item-Based Collaborative Filtering - Rating user gave for simlair items"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "48ee2efd",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2024-01-04T20:48:37.507394100Z",
          "start_time": "2024-01-04T20:48:37.378938400Z"
        },
        "id": "48ee2efd"
      },
      "outputs": [],
      "source": [
        "train = train_processed\n",
        "val = val_processed\n",
        "test = test_processed"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "08216ac9",
      "metadata": {
        "id": "08216ac9"
      },
      "source": [
        "# Feature Engineering - from current features"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b52b8b6a",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2024-01-04T20:48:37.915744500Z",
          "start_time": "2024-01-04T20:48:37.470367700Z"
        },
        "id": "b52b8b6a"
      },
      "outputs": [],
      "source": [
        "numeric_cols = [col for col in train.describe().columns if not 'sim_' in col]\n",
        "numeric_cols"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8b2aa29c",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2024-01-04T20:48:38.203907600Z",
          "start_time": "2024-01-04T20:48:37.641271900Z"
        },
        "id": "8b2aa29c"
      },
      "outputs": [],
      "source": [
        "train_user_stats_for_new_features = train.groupby('userName')[numeric_cols].agg(['min','mean','median','max','std']).fillna(0)\n",
        "train_user_stats_for_new_features.columns = [a + \"_\" + b for a,b in train_user_stats_for_new_features.columns]\n",
        "train_user_stats_for_new_features = train_user_stats_for_new_features.add_prefix('user_')\n",
        "train_user_stats_for_new_features"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "75df7f79",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2024-01-04T20:48:39.711580800Z",
          "start_time": "2024-01-04T20:48:38.192451900Z"
        },
        "id": "75df7f79"
      },
      "outputs": [],
      "source": [
        "train_item_stats_for_new_features = train.groupby('item_id')[numeric_cols].agg(['min','mean','median','max','std']).fillna(0)\n",
        "train_item_stats_for_new_features.columns = [a + \"_\" + b for a,b in train_item_stats_for_new_features.columns]\n",
        "train_item_stats_for_new_features = train_item_stats_for_new_features.add_prefix('item_')\n",
        "train_item_stats_for_new_features"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "371b4fee",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2024-01-04T20:48:39.735350800Z",
          "start_time": "2024-01-04T20:48:38.955350Z"
        },
        "id": "371b4fee"
      },
      "outputs": [],
      "source": [
        "train.shape, val.shape, test.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "79b8a1be",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2024-01-04T20:48:40.928843300Z",
          "start_time": "2024-01-04T20:48:38.970733200Z"
        },
        "id": "79b8a1be"
      },
      "outputs": [],
      "source": [
        "train = train.merge(train_user_stats_for_new_features, on='userName', how='left')\n",
        "train = train.merge(train_item_stats_for_new_features, on='item_id', how='left')\n",
        "\n",
        "val = val.merge(train_user_stats_for_new_features, on='userName', how='left').fillna(0)\n",
        "val = val.merge(train_item_stats_for_new_features, on='item_id', how='left').fillna(0)\n",
        "test = test.merge(train_user_stats_for_new_features, on='userName', how='left').fillna(0)\n",
        "test = test.merge(train_item_stats_for_new_features, on='item_id', how='left').fillna(0)\n",
        "\n",
        "train.shape, val.shape, test.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "befc064b",
      "metadata": {
        "id": "befc064b"
      },
      "source": [
        "# Drop features that are specific to review (and not to users or items)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b5459477",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2024-01-04T20:48:41.340426100Z",
          "start_time": "2024-01-04T20:48:40.369251500Z"
        },
        "id": "b5459477"
      },
      "outputs": [],
      "source": [
        "train.shape, val.shape, test.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7051788e",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2024-01-04T20:48:41.491307600Z",
          "start_time": "2024-01-04T20:48:40.384374100Z"
        },
        "id": "7051788e"
      },
      "outputs": [],
      "source": [
        "users_items_features_and_target = train.columns[train.columns.str.contains('user|item|brand|category')].tolist() + [target]\n",
        "users_items_features_and_target = [col for col in users_items_features_and_target if col in val.columns if col in test.columns]\n",
        "train = train[users_items_features_and_target]\n",
        "val = val[users_items_features_and_target]\n",
        "test = test[users_items_features_and_target]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3bd61ef4",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2024-01-04T20:48:41.529984800Z",
          "start_time": "2024-01-04T20:48:40.860585400Z"
        },
        "id": "3bd61ef4"
      },
      "outputs": [],
      "source": [
        "train.shape, val.shape, test.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "66bfc26b",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2024-01-04T20:48:41.567361200Z",
          "start_time": "2024-01-04T20:48:40.875383300Z"
        },
        "id": "66bfc26b"
      },
      "outputs": [],
      "source": [
        "users_items_features_and_target"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "02ba1829",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2024-01-04T20:48:41.651310600Z",
          "start_time": "2024-01-04T20:48:40.891144600Z"
        },
        "id": "02ba1829"
      },
      "outputs": [],
      "source": [
        "import gc\n",
        "gc.collect()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a36edb49",
      "metadata": {
        "id": "a36edb49"
      },
      "source": [
        "# Some more EDA of final features"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "baa5028d",
      "metadata": {
        "id": "baa5028d"
      },
      "source": [
        "## NA's and dtypes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bddbc1fa",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2024-01-04T20:57:25.252555300Z",
          "start_time": "2024-01-04T20:57:24.995507500Z"
        },
        "id": "bddbc1fa"
      },
      "outputs": [],
      "source": [
        "# Those we already marked NA and probably didn't survised the export and import from csv after the collaborative filtering features\n",
        "train.loc[train.brand.isna(), 'brand'] = 'NA'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cb1ecae2",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2024-01-04T20:57:37.856553800Z",
          "start_time": "2024-01-04T20:57:37.630970200Z"
        },
        "id": "cb1ecae2"
      },
      "outputs": [],
      "source": [
        "assert train.isna().sum().sum() == 0\n",
        "assert val.isna().sum().sum() == 0\n",
        "assert test.isna().sum().sum() == 0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d1c8f8ad",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2024-01-04T20:57:49.519816400Z",
          "start_time": "2024-01-04T20:57:49.071487Z"
        },
        "id": "d1c8f8ad"
      },
      "outputs": [],
      "source": [
        "train.info()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ffa3c669",
      "metadata": {
        "id": "ffa3c669"
      },
      "source": [
        "## statistics"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ff3001f3",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2024-01-04T20:57:51.127424400Z",
          "start_time": "2024-01-04T20:57:49.103421700Z"
        },
        "id": "ff3001f3"
      },
      "outputs": [],
      "source": [
        "train.describe(include='all')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ae3df496",
      "metadata": {
        "id": "ae3df496"
      },
      "source": [
        "## nunique values"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d355cb06",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2024-01-04T20:57:51.879062800Z",
          "start_time": "2024-01-04T20:57:50.808084900Z"
        },
        "id": "d355cb06"
      },
      "outputs": [],
      "source": [
        "print(train.nunique())"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6d070198",
      "metadata": {
        "id": "6d070198"
      },
      "source": [
        "## modes frequencies"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "01519490",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2024-01-04T20:57:53.156087900Z",
          "start_time": "2024-01-04T20:57:51.452186200Z"
        },
        "id": "01519490"
      },
      "outputs": [],
      "source": [
        "get_mode_and_freq(train)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "85da114d",
      "metadata": {
        "id": "85da114d"
      },
      "source": [
        "## plots"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "025ad6d8",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2024-01-04T20:57:53.506504700Z",
          "start_time": "2024-01-04T20:57:52.218406500Z"
        },
        "id": "025ad6d8"
      },
      "outputs": [],
      "source": [
        "#train = pd.concat([train.reset_index(drop=True), y_train.reset_index(drop=True)], axis=1)\n",
        "train_small = train.sample(frac=0.01)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5f595b04",
      "metadata": {
        "id": "5f595b04"
      },
      "source": [
        "### features relationship with features - not exectued, takes too long to run"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1cf3c11b",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2024-01-04T20:57:53.717020200Z",
          "start_time": "2024-01-04T20:57:52.248171Z"
        },
        "id": "1cf3c11b"
      },
      "outputs": [],
      "source": [
        "#numeric_cols = train_small.describe().columns\n",
        "#numeric_cols"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1b874cc7",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2024-01-04T20:57:53.879299900Z",
          "start_time": "2024-01-04T20:57:52.263516100Z"
        },
        "id": "1b874cc7"
      },
      "outputs": [],
      "source": [
        "#train_small[numeric_cols][:10]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2a3bafdc",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2024-01-04T20:57:53.924424500Z",
          "start_time": "2024-01-04T20:57:52.279298700Z"
        },
        "id": "2a3bafdc"
      },
      "outputs": [],
      "source": [
        "# sns.pairplot()\n",
        "# plt.show()\n",
        "# #plt.tight_layout()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0bc9e761",
      "metadata": {
        "id": "0bc9e761"
      },
      "source": [
        "### features relationship with target  - not exectued, takes too long to run"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e106b881",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2024-01-04T20:57:54.111130200Z",
          "start_time": "2024-01-04T20:57:52.295173500Z"
        },
        "id": "e106b881"
      },
      "outputs": [],
      "source": [
        "# sns.pairplot(train_small[:100], hue=target)\n",
        "# plt.show()\n",
        "# #plt.tight_layout()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c23ca345",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2024-01-04T20:57:54.155555500Z",
          "start_time": "2024-01-04T20:57:52.309427700Z"
        },
        "id": "c23ca345"
      },
      "outputs": [],
      "source": [
        "train.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "44b90cba",
      "metadata": {
        "id": "44b90cba"
      },
      "source": [
        "## Correlations"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "81621403",
      "metadata": {
        "id": "81621403"
      },
      "source": [
        "## Pearson - linear correlation between two continuous variables"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f20357a4",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2024-01-04T20:58:47.422189600Z",
          "start_time": "2024-01-04T20:57:52.325251800Z"
        },
        "id": "f20357a4"
      },
      "outputs": [],
      "source": [
        "corr_features = get_correlation_stats(train, method='pearson', strong_corr_val = 0.5, figsize=(14,10), annot=False)\n",
        "corr_features"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c72d7deb",
      "metadata": {
        "id": "c72d7deb"
      },
      "source": [
        "#### # Drop features that are almost perfect multicollinear (corr over 0.9)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6c56f361",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2024-01-04T20:58:47.472899800Z",
          "start_time": "2024-01-04T20:58:47.359770800Z"
        },
        "id": "6c56f361"
      },
      "outputs": [],
      "source": [
        "corr_features_to_drop = corr_features.drop(columns=target, errors='ignore')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7d8239c5",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2024-01-04T20:58:48.729215200Z",
          "start_time": "2024-01-04T20:58:47.374001700Z"
        },
        "id": "7d8239c5"
      },
      "outputs": [],
      "source": [
        "# Identify highly correlated features\n",
        "to_drop = set()\n",
        "for i in range(len(corr_features_to_drop.columns)):\n",
        "    for j in range(i+1, len(corr_features.columns)):\n",
        "        if abs(corr_features.iloc[i, j]) > 0.9:\n",
        "            colname = corr_features.columns[i]\n",
        "            to_drop.add(colname)\n",
        "\n",
        "\n",
        "# Drop identified features from the original DataFrame\n",
        "train = train.drop(columns=to_drop)\n",
        "val = val.drop(columns=to_drop)\n",
        "test = test.drop(columns=to_drop)\n",
        "train.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1ee654d5",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2024-01-04T20:59:25.256131200Z",
          "start_time": "2024-01-04T20:58:48.706545200Z"
        },
        "id": "1ee654d5"
      },
      "outputs": [],
      "source": [
        "corr_features = get_correlation_stats(train, method='pearson', strong_corr_val = 0.5, figsize=(14,10), annot=False)\n",
        "corr_features"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c45cc54f",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2024-01-04T20:59:25.299661900Z",
          "start_time": "2024-01-04T20:59:25.115088400Z"
        },
        "id": "c45cc54f"
      },
      "outputs": [],
      "source": [
        "corr_features[target] if target in corr_features else \"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1e3b5442",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2024-01-04T20:59:25.529736Z",
          "start_time": "2024-01-04T20:59:25.128176100Z"
        },
        "id": "1e3b5442"
      },
      "outputs": [],
      "source": [
        "train.shape, val.shape, test.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6a45f3dc",
      "metadata": {
        "id": "6a45f3dc"
      },
      "source": [
        "## Spearman - \"rank pearson\" - non-linear correlation between two continuous or ordinal variables"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0b286df2",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2024-01-04T20:59:25.601739Z",
          "start_time": "2024-01-04T20:59:25.143503800Z"
        },
        "id": "0b286df2"
      },
      "outputs": [],
      "source": [
        "#corr_features = get_correlation_stats(X_train, method='spearman', strong_corr_val=0.5, figsize=(14,10), annot=False)\n",
        "#corr_features"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0dcb28a1",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2024-01-04T20:59:25.638852600Z",
          "start_time": "2024-01-04T20:59:25.158743600Z"
        },
        "id": "0dcb28a1"
      },
      "outputs": [],
      "source": [
        "#corr_features[target] if target in corr_features else \"\""
      ]
    },
    {
      "cell_type": "markdown",
      "id": "87a98d4f",
      "metadata": {
        "id": "87a98d4f"
      },
      "source": [
        "## Kendall - concordant pairs - non-linear correlation between two ordinal variables"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "971c7109",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2024-01-04T20:59:25.667078Z",
          "start_time": "2024-01-04T20:59:25.175200700Z"
        },
        "id": "971c7109"
      },
      "outputs": [],
      "source": [
        "#corr_features = get_correlation_stats(X_train, method='kendall', strong_corr_val=0.4, figsize=(14,10), annot=False)\n",
        "#corr_features"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4f2845f1",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2024-01-04T20:59:25.682880500Z",
          "start_time": "2024-01-04T20:59:25.190352700Z"
        },
        "id": "4f2845f1"
      },
      "outputs": [],
      "source": [
        "#corr_features[target] if target in corr_features else \"\""
      ]
    },
    {
      "cell_type": "markdown",
      "id": "498f11eb",
      "metadata": {
        "id": "498f11eb"
      },
      "source": [
        "## # Only statistics on user and item from rating have strong correlation to target. perhaps we need feature combinations, new features (user startistics, item statistics, sentiment) or a different approach - a collaborative filtering recommender system"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4d9029c9",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2024-01-04T20:59:25.715167500Z",
          "start_time": "2024-01-04T20:59:25.204628100Z"
        },
        "id": "4d9029c9"
      },
      "outputs": [],
      "source": [
        "# ## Test if train statistics are different then val and test statistics\n",
        "# trains_dict_to_test = {'val': val, 'test': test}\n",
        "# train_val_outlier_means_test = test_if_features_statistically_different(train, trains_dict_to_test, alpha=alpha)\n",
        "# print('\\n# Test if train, validation and test sets means are statisically not different:\\n',\n",
        "#       train_val_outlier_means_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a041b629",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2024-01-04T20:59:25.742508700Z",
          "start_time": "2024-01-04T20:59:25.221384400Z"
        },
        "id": "a041b629"
      },
      "outputs": [],
      "source": [
        "#sum(train_val_outlier_means_test['val mean is the same with 99% significance']==True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9222b1c8",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2024-01-04T20:59:25.757514500Z",
          "start_time": "2024-01-04T20:59:25.235496300Z"
        },
        "id": "9222b1c8"
      },
      "outputs": [],
      "source": [
        "#sum(train_val_outlier_means_test['val mean is the same with 99% significance']==False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "febff801",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2024-01-04T20:59:25.854939800Z",
          "start_time": "2024-01-04T20:59:25.252782100Z"
        },
        "id": "febff801"
      },
      "outputs": [],
      "source": [
        "#sum(train_val_outlier_means_test['test mean is the same with 99% significance']==True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "33c71878",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2024-01-04T20:59:25.884936300Z",
          "start_time": "2024-01-04T20:59:25.265991600Z"
        },
        "id": "33c71878"
      },
      "outputs": [],
      "source": [
        "#sum(train_val_outlier_means_test['test mean is the same with 99% significance']==False)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8c7ddbab",
      "metadata": {
        "id": "8c7ddbab"
      },
      "source": [
        "## # about half the features have different distribution for train and test. this might cause bias in predictions, consider removing those"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4a815888",
      "metadata": {
        "id": "4a815888"
      },
      "source": [
        "# Normalize dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "96c3c65b",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2024-01-04T20:59:26.914686100Z",
          "start_time": "2024-01-04T20:59:25.287056100Z"
        },
        "id": "96c3c65b"
      },
      "outputs": [],
      "source": [
        "features = train.drop(columns=target).describe().columns.tolist()\n",
        "len(features), features"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "02463b94",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2024-01-04T20:59:26.945491700Z",
          "start_time": "2024-01-04T20:59:26.556545100Z"
        },
        "id": "02463b94"
      },
      "outputs": [],
      "source": [
        "[col for col in features if 'sim' in col]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2c387346",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2024-01-04T20:59:27.022509Z",
          "start_time": "2024-01-04T20:59:26.571868900Z"
        },
        "id": "2c387346"
      },
      "outputs": [],
      "source": [
        "X_train = train.drop(columns=target)\n",
        "y_train = train[target]\n",
        "\n",
        "X_val = val.drop(columns=target)\n",
        "y_val = val[target]\n",
        "\n",
        "X_test = test.drop(columns=target)\n",
        "y_test = test[target]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3b7897c7",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2024-01-04T20:59:27.937043900Z",
          "start_time": "2024-01-04T20:59:26.742321900Z"
        },
        "id": "3b7897c7"
      },
      "outputs": [],
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "# Initialize the scaler\n",
        "scaler = StandardScaler()\n",
        "\n",
        "# Fit on training data\n",
        "scaler.fit(X_train[features])\n",
        "\n",
        "# Transform the datasets\n",
        "X_train_scaled = scaler.transform(X_train[features])\n",
        "X_val_scaled = scaler.transform(X_val[features])\n",
        "X_test_scaled = scaler.transform(X_test[features])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cf7d631d",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2024-01-04T20:59:28.138700700Z",
          "start_time": "2024-01-04T20:59:27.938120200Z"
        },
        "id": "cf7d631d"
      },
      "outputs": [],
      "source": [
        "X_train_scaled = pd.DataFrame(X_train_scaled)\n",
        "X_train_scaled.columns = features\n",
        "\n",
        "X_val_scaled = pd.DataFrame(X_val_scaled)\n",
        "X_val_scaled.columns = features\n",
        "\n",
        "X_test_scaled = pd.DataFrame(X_test_scaled)\n",
        "\n",
        "X_test_scaled.columns = features\n",
        "\n",
        "X_train_scaled"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3c0a1b2a",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2024-01-04T20:59:28.877702600Z",
          "start_time": "2024-01-04T20:59:28.136528600Z"
        },
        "id": "3c0a1b2a"
      },
      "outputs": [],
      "source": [
        "X_train_scaled.agg(['mean','std']).round(2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0f333802",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2024-01-04T20:59:28.895351900Z",
          "start_time": "2024-01-04T20:59:28.719717700Z"
        },
        "id": "0f333802"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "id": "7644aa81",
      "metadata": {
        "id": "7644aa81"
      },
      "source": [
        "# final preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5e853d59",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2024-01-04T20:59:29.050050800Z",
          "start_time": "2024-01-04T20:59:28.735803300Z"
        },
        "id": "5e853d59"
      },
      "outputs": [],
      "source": [
        "# # fix columns names\n",
        "# X_train = replace_columns_spaces_with_underscores(X_train)\n",
        "# X_val = replace_columns_spaces_with_underscores(X_val)\n",
        "# X_test = replace_columns_spaces_with_underscores(X_test)\n",
        "# train_statistics = replace_columns_spaces_with_underscores(train_statistics.T).T"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "674202cb",
      "metadata": {
        "id": "674202cb"
      },
      "source": [
        "# Modeling"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1fd6a1c8",
      "metadata": {
        "id": "1fd6a1c8"
      },
      "source": [
        "## Basline model - mean rating per user"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c8febeed",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2024-01-04T20:59:29.413335200Z",
          "start_time": "2024-01-04T20:59:28.751797500Z"
        },
        "id": "c8febeed"
      },
      "outputs": [],
      "source": [
        "train = pd.concat([X_train_scaled, y_train], axis=1)\n",
        "train.index = X_train['userName']\n",
        "\n",
        "val = pd.concat([X_val_scaled, y_val], axis=1)\n",
        "val.index = X_val['userName']\n",
        "\n",
        "test = pd.concat([X_test_scaled, y_test], axis=1)\n",
        "test.index = X_test['userName']\n",
        "\n",
        "train[train.index == 'Amazossn Customerccocooper17o']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2f00211c",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2024-01-04T20:59:29.792172300Z",
          "start_time": "2024-01-04T20:59:29.212417500Z"
        },
        "id": "2f00211c"
      },
      "outputs": [],
      "source": [
        "baseline_pred_dict = train.groupby('userName')[target].mean().to_dict()\n",
        "baseline_pred_dict"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "250ba805",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2024-01-04T20:59:30.102838900Z",
          "start_time": "2024-01-04T20:59:29.257205Z"
        },
        "id": "250ba805"
      },
      "outputs": [],
      "source": [
        "val[~val.index.isin(train.index)]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4a0be9d1",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2024-01-04T20:59:30.192422400Z",
          "start_time": "2024-01-04T20:59:29.555362600Z"
        },
        "id": "4a0be9d1"
      },
      "outputs": [],
      "source": [
        "val.index.nunique()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "81ae5fcb",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2024-01-04T20:59:30.227921800Z",
          "start_time": "2024-01-04T20:59:29.564033Z"
        },
        "id": "81ae5fcb"
      },
      "outputs": [],
      "source": [
        "val[~val.index.isin(train.index)].index.nunique()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4dff57c6",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2024-01-04T20:59:30.256012200Z",
          "start_time": "2024-01-04T20:59:29.578853500Z"
        },
        "id": "4dff57c6"
      },
      "outputs": [],
      "source": [
        "218/23751"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "39460125",
      "metadata": {
        "id": "39460125"
      },
      "source": [
        "### # drop 0.9% val users (218) that are not in train - so that the comparison of baseline to other models will be fair"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3542b69b",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2024-01-04T20:59:30.270498500Z",
          "start_time": "2024-01-04T20:59:29.605341100Z"
        },
        "id": "3542b69b"
      },
      "outputs": [],
      "source": [
        "val = val[val.index.isin(train.index)]\n",
        "X_val = X_val[X_val['userName'].isin(val.index)]\n",
        "X_val.index = val.index"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1456ac22",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2024-01-04T20:59:30.301176200Z",
          "start_time": "2024-01-04T20:59:29.671374500Z"
        },
        "id": "1456ac22"
      },
      "outputs": [],
      "source": [
        "# val_n_ratings = val.groupby('userName').size()\n",
        "# val_n_ratings.value_counts(normalize=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "55c63ebe",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2024-01-04T20:59:30.398328900Z",
          "start_time": "2024-01-04T20:59:29.686748600Z"
        },
        "id": "55c63ebe"
      },
      "outputs": [],
      "source": [
        "# val0 = val.copy(deep=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "36ece4ee",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2024-01-04T20:59:30.430046300Z",
          "start_time": "2024-01-04T20:59:29.702677700Z"
        },
        "id": "36ece4ee"
      },
      "outputs": [],
      "source": [
        "## drop val users without 5 ratings - we need to test if prediction is good for user's top 5 ratings"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b60eb5d5",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2024-01-04T20:59:30.447186800Z",
          "start_time": "2024-01-04T20:59:29.716949700Z"
        },
        "id": "b60eb5d5"
      },
      "outputs": [],
      "source": [
        "# val = val[val.index.isin(val_n_ratings[val_n_ratings>=5].index)]\n",
        "# X_val = X_val[X_val.index.isin(val_n_ratings[val_n_ratings>=5].index)]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fcbd9393",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2024-01-04T20:59:30.506831400Z",
          "start_time": "2024-01-04T20:59:29.732277900Z"
        },
        "id": "fcbd9393"
      },
      "outputs": [],
      "source": [
        "pred_col = f'{target}_pred_baseline'\n",
        "val[f'{target}_pred_baseline'] = val.index.map(baseline_pred_dict)\n",
        "val[[target, pred_col]]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "792ff75a",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2024-01-04T21:00:10.223305200Z",
          "start_time": "2024-01-04T21:00:09.813462600Z"
        },
        "id": "792ff75a"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import max_error\n",
        "from sklearn.metrics import mean_absolute_error\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from sklearn.metrics import mean_absolute_percentage_error\n",
        "from sklearn.metrics import r2_score\n",
        "\n",
        "def get_regression_metrics(the_df, target_col, pred_col, the_metrics_df=None, regression_metrics=None, model_name='baseline'):\n",
        "    if regression_metrics is None:\n",
        "        regression_metrics = [mean_absolute_error, max_error, mean_absolute_percentage_error, mean_squared_error, r2_score]\n",
        "    the_metrics_df = pd.DataFrame() if the_metrics_df is None else the_metrics_df\n",
        "    the_metrics = {}\n",
        "    the_metrics['userName'] = the_df.index.nunique()\n",
        "    the_metrics['item_ids'] = the_df['item_id'].nunique()\n",
        "    the_metrics[f'mean_{target}'] = the_df[target_col].mean()\n",
        "    for metric in regression_metrics:\n",
        "        the_metrics[metric.__name__] = metric(the_df[target_col], the_df[pred_col])\n",
        "    the_df[f'{pred_col}_error_abs'] = (the_df[target] - the_df[pred_col]).abs()\n",
        "    bins_error_abs = the_df.groupby(target)[f'{pred_col}_error_abs'].mean().add_prefix(f\"{target}_\").add_suffix(\"_error\").to_dict()\n",
        "    the_df = the_df.drop(columns=[f'{pred_col}_error_abs'])\n",
        "    the_metrics.update(bins_error_abs)\n",
        "    the_metrics = pd.DataFrame.from_dict(the_metrics, columns=[model_name], orient='index').T\n",
        "    the_metrics_df = pd.concat([the_metrics_df, the_metrics], axis=0)\n",
        "\n",
        "\n",
        "    return the_metrics_df\n",
        "\n",
        "metrics = pd.DataFrame()\n",
        "metrics = get_regression_metrics(pd.concat([val, X_val['item_id']], axis=1), target, f'{target}_pred_baseline')\n",
        "metrics"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1fc368fb",
      "metadata": {
        "id": "1fc368fb"
      },
      "source": [
        "## Linear regression - worse than baseline, very bad, coefficients are crazy big. we have many features with zero importance, we'll do LASSO next for features selection, we have many features"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "04fe4b23",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2024-01-04T21:00:24.955296300Z",
          "start_time": "2024-01-04T21:00:23.323121400Z"
        },
        "id": "04fe4b23"
      },
      "outputs": [],
      "source": [
        "from sklearn.linear_model import LinearRegression\n",
        "\n",
        "reg = LinearRegression(n_jobs=-1).fit(train.drop(columns=target), train[target])\n",
        "reg.score(train.drop(columns=target), train[target])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5d53c515",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2024-01-04T21:00:25.576359900Z",
          "start_time": "2024-01-04T21:00:24.954792Z"
        },
        "id": "5d53c515"
      },
      "outputs": [],
      "source": [
        "pd.set_option('display.float_format', '{:.3f}'.format)\n",
        "coefs = reg.coef_\n",
        "features_importance = pd.DataFrame(coefs, columns=['importance'], index=features).round(3)\n",
        "features_importance['importance_abs'] = features_importance['importance'].abs()\n",
        "features_importance = features_importance.sort_values('importance_abs', ascending=False)\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Assuming 'model' is your fitted Linear Regression model and 'feature_names' is a list of feature names\n",
        "display(features_importance)\n",
        "\n",
        "# Create a plot\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.barh(features_importance.head(20).index[::-1], features_importance.head(20)[::-1]['importance'])\n",
        "plt.xlabel('Coefficient Value')\n",
        "plt.ylabel('Feature')\n",
        "plt.title('Linear Regression Feature Importance')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "72303d33",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2024-01-04T21:00:25.801748100Z",
          "start_time": "2024-01-04T21:00:25.213567200Z"
        },
        "id": "72303d33"
      },
      "outputs": [],
      "source": [
        "pred_col = f'{target}_pred_{reg.__str__()}'\n",
        "val[pred_col] = reg.predict(val.drop(columns=[col for col in val if col==target or 'pred' in col]))\n",
        "val[[target]+[col for col in val.columns if 'pred' in col]]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8d80bf4b",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2024-01-04T21:00:25.839293500Z",
          "start_time": "2024-01-04T21:00:25.305707500Z"
        },
        "id": "8d80bf4b"
      },
      "outputs": [],
      "source": [
        "model_name = reg.__str__()\n",
        "the_df = pd.concat([val, X_val['item_id']], axis=1)\n",
        "target_col = target\n",
        "the_metrics_df = metrics\n",
        "regression_metrics = None\n",
        "metrics = get_regression_metrics(the_df, target_col, pred_col, the_metrics_df, regression_metrics, model_name)\n",
        "metrics"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "25631067",
      "metadata": {
        "id": "25631067"
      },
      "source": [
        "## Linear regression - Lasso - worse than baseline, only one important feature - item_rating_mean. Perhaps need something more comple like RF"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "71571b1e",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2024-01-04T21:00:26.815029600Z",
          "start_time": "2024-01-04T21:00:25.381675400Z"
        },
        "id": "71571b1e"
      },
      "outputs": [],
      "source": [
        "from sklearn import linear_model\n",
        "\n",
        "reg = linear_model.Lasso(alpha=0.5).fit(train.drop(columns=target), train[target])\n",
        "reg.score(train.drop(columns=target), train[target])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cab99251",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2024-01-04T21:00:27.080166900Z",
          "start_time": "2024-01-04T21:00:26.199018200Z"
        },
        "id": "cab99251"
      },
      "outputs": [],
      "source": [
        "pd.set_option('display.float_format', '{:.3f}'.format)\n",
        "coefs = reg.coef_\n",
        "features_importance = pd.DataFrame(coefs, columns=['importance'], index=features).round(3)\n",
        "features_importance['importance_abs'] = features_importance['importance'].abs()\n",
        "features_importance = features_importance.sort_values('importance_abs', ascending=False)\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Assuming 'model' is your fitted Linear Regression model and 'feature_names' is a list of feature names\n",
        "display(features_importance)\n",
        "\n",
        "# Create a plot\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.barh(features_importance.head(20).index[::-1], features_importance.head(20)[::-1]['importance'])\n",
        "plt.xlabel('Coefficient Value')\n",
        "plt.ylabel('Feature')\n",
        "plt.title('Linear Regression Feature Importance')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "642b6538",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2024-01-04T21:00:27.221231700Z",
          "start_time": "2024-01-04T21:00:26.441786400Z"
        },
        "id": "642b6538"
      },
      "outputs": [],
      "source": [
        "pred_col = f'{target}_pred_{reg.__str__()}'\n",
        "val[pred_col] = reg.predict(val.drop(columns=[col for col in val if col==target or 'pred' in col]))\n",
        "val[[target]+[col for col in val.columns if 'pred' in col]]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "15f078d8",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2024-01-04T21:00:27.658305500Z",
          "start_time": "2024-01-04T21:00:26.534305300Z"
        },
        "id": "15f078d8"
      },
      "outputs": [],
      "source": [
        "model_name = reg.__str__()\n",
        "the_df = pd.concat([val, X_val['item_id']], axis=1)\n",
        "target_col = target\n",
        "the_metrics_df = metrics\n",
        "regression_metrics = None\n",
        "metrics = get_regression_metrics(the_df, target_col, pred_col, the_metrics_df, regression_metrics, model_name)\n",
        "metrics"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "30f88447",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2024-01-04T21:00:27.803748200Z",
          "start_time": "2024-01-04T21:00:26.611914100Z"
        },
        "id": "30f88447"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "id": "a174c3d4",
      "metadata": {
        "id": "a174c3d4"
      },
      "source": [
        "## Random Forest Regressor - for max_depth=2 still worse than baseline, but 3 important features."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7ee8cefb",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2024-01-04T21:14:23.147921800Z",
          "start_time": "2024-01-04T21:14:11.713296400Z"
        },
        "id": "7ee8cefb"
      },
      "outputs": [],
      "source": [
        "from sklearn.ensemble import RandomForestRegressor\n",
        "\n",
        "regr = RandomForestRegressor(max_depth=2, random_state=0, n_jobs=-1)\n",
        "regr.fit(train.drop(columns=target), train[target])\n",
        "regr.score(train.drop(columns=target), train[target])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b66d8919",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2024-01-04T21:00:40.641873500Z",
          "start_time": "2024-01-04T21:00:40.397023800Z"
        },
        "id": "b66d8919"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Assuming 'rf_model' is your trained Random Forest model\n",
        "# and 'feature_names' is a list of your feature names\n",
        "\n",
        "# Get feature importances\n",
        "importances = regr.feature_importances_\n",
        "\n",
        "# Create a DataFrame for easier handling\n",
        "feature_importances = pd.DataFrame({'Feature': features, 'Importance': importances})\n",
        "\n",
        "# Sort by importance\n",
        "feature_importances = feature_importances.sort_values(by='Importance', ascending=False)\n",
        "\n",
        "feature_importances = feature_importances.head(20)\n",
        "# Plot\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.barh(feature_importances['Feature'], feature_importances['Importance'])\n",
        "plt.xlabel('Importance')\n",
        "plt.ylabel('Feature')\n",
        "plt.title('Random Forest Feature Importances')\n",
        "plt.gca().invert_yaxis()  # To display the highest importance at the top\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "48da9f0d",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2024-01-04T21:00:40.878142800Z",
          "start_time": "2024-01-04T21:00:40.643544600Z"
        },
        "id": "48da9f0d"
      },
      "outputs": [],
      "source": [
        "pred_col = f'{target}_pred_{regr.__str__()}'\n",
        "val[pred_col] = regr.predict(val.drop(columns=[col for col in val if col==target or 'pred' in col]))\n",
        "val[[target]+[col for col in val.columns if 'pred' in col]]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9595fc09",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2024-01-04T21:00:41.002793100Z",
          "start_time": "2024-01-04T21:00:40.765021300Z"
        },
        "id": "9595fc09"
      },
      "outputs": [],
      "source": [
        "model_name = regr.__str__()\n",
        "the_df = pd.concat([val, X_val['item_id']], axis=1)\n",
        "target_col = target\n",
        "the_metrics_df = metrics\n",
        "regression_metrics = None\n",
        "metrics = get_regression_metrics(the_df, target_col, pred_col, the_metrics_df, regression_metrics, model_name)\n",
        "metrics"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "05f066de",
      "metadata": {
        "id": "05f066de"
      },
      "outputs": [],
      "source": [
        "## For max_depth=None, better than baseline on MAE and lower bins, a lot of important features - but might overfit?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7666e2ad",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2024-01-04T21:12:59.536721Z",
          "start_time": "2024-01-04T21:12:33.513829900Z"
        },
        "id": "7666e2ad"
      },
      "outputs": [],
      "source": [
        "from sklearn.ensemble import RandomForestRegressor\n",
        "\n",
        "regr = RandomForestRegressor(random_state=0, n_jobs=-1)\n",
        "regr.fit(train.drop(columns=target), train[target])\n",
        "regr.score(train.drop(columns=target), train[target])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0b7b4601",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2024-01-04T21:03:54.649565500Z",
          "start_time": "2024-01-04T21:03:54.428654600Z"
        },
        "id": "0b7b4601"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Assuming 'rf_model' is your trained Random Forest model\n",
        "# and 'feature_names' is a list of your feature names\n",
        "\n",
        "# Get feature importances\n",
        "importances = regr.feature_importances_\n",
        "\n",
        "# Create a DataFrame for easier handling\n",
        "feature_importances = pd.DataFrame({'Feature': features, 'Importance': importances})\n",
        "\n",
        "# Sort by importance\n",
        "feature_importances = feature_importances.sort_values(by='Importance', ascending=False)\n",
        "\n",
        "feature_importances = feature_importances.head(20)\n",
        "# Plot\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.barh(feature_importances['Feature'], feature_importances['Importance'])\n",
        "plt.xlabel('Importance')\n",
        "plt.ylabel('Feature')\n",
        "plt.title('Random Forest Feature Importances')\n",
        "plt.gca().invert_yaxis()  # To display the highest importance at the top\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e950f60c",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2024-01-04T21:03:54.856631500Z",
          "start_time": "2024-01-04T21:03:54.642319500Z"
        },
        "id": "e950f60c"
      },
      "outputs": [],
      "source": [
        "pred_col = f'{target}_pred_{regr.__str__()}'\n",
        "val[pred_col] = regr.predict(val.drop(columns=[col for col in val if col==target or 'pred' in col]))\n",
        "val[[target]+[col for col in val.columns if 'pred' in col]]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "eb9a7e02",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2024-01-04T21:03:55.271153700Z",
          "start_time": "2024-01-04T21:03:54.850582Z"
        },
        "id": "eb9a7e02"
      },
      "outputs": [],
      "source": [
        "model_name = regr.__str__()\n",
        "the_df = pd.concat([val, X_val['item_id']], axis=1)\n",
        "target_col = target\n",
        "the_metrics_df = metrics\n",
        "regression_metrics = None\n",
        "metrics = get_regression_metrics(the_df, target_col, pred_col, the_metrics_df, regression_metrics, model_name)\n",
        "metrics"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "92b19206",
      "metadata": {
        "id": "92b19206"
      },
      "source": [
        "## LightGBM - many important features, bad predictions. default hyperparameters are overfitting. We'll do a grid search"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9ab18bde",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2024-01-04T21:04:00.606879500Z",
          "start_time": "2024-01-04T21:03:54.928999300Z"
        },
        "id": "9ab18bde"
      },
      "outputs": [],
      "source": [
        "import lightgbm as lgb\n",
        "\n",
        "lgbm = lgb.LGBMRegressor()\n",
        "old_columns = train.columns.copy(deep=True)\n",
        "# Replace unsupported characters with an underscore or remove them\n",
        "train.columns = [\"\".join(c if c.isalnum() else \"_\" for c in str(x)) for x in train.columns]\n",
        "\n",
        "lgbm.fit(train.drop(columns=target), train[target])\n",
        "lgbm.score(train.drop(columns=target), train[target])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "815721f2",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2024-01-04T21:04:01.156020400Z",
          "start_time": "2024-01-04T21:04:00.599306Z"
        },
        "id": "815721f2"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Assuming 'rf_model' is your trained Random Forest model\n",
        "# and 'feature_names' is a list of your feature names\n",
        "\n",
        "# Get feature importances\n",
        "importances = lgbm.feature_importances_\n",
        "\n",
        "# Create a DataFrame for easier handling\n",
        "feature_importances = pd.DataFrame({'Feature': features, 'Importance': importances})\n",
        "\n",
        "# Sort by importance\n",
        "feature_importances = feature_importances.sort_values(by='Importance', ascending=False)\n",
        "\n",
        "feature_importances = feature_importances.head(20)\n",
        "# Plot\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.barh(feature_importances['Feature'], feature_importances['Importance'])\n",
        "plt.xlabel('Importance')\n",
        "plt.ylabel('Feature')\n",
        "plt.title(f'LGBM Feature Importances')\n",
        "plt.gca().invert_yaxis()  # To display the highest importance at the top\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "de1f1a98",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2024-01-04T21:04:01.278989200Z",
          "start_time": "2024-01-04T21:04:01.150030900Z"
        },
        "id": "de1f1a98"
      },
      "outputs": [],
      "source": [
        "pred_col = f'{target}_pred_{lgbm.__str__()}'\n",
        "old_columns_val = val.columns.copy(deep=True)\n",
        "# Replace unsupported characters with an underscore or remove them\n",
        "val.columns = [\"\".join(c if c.isalnum() else \"_\" for c in str(x)) for x in val.columns]\n",
        "\n",
        "val[pred_col] = lgbm.predict(val.drop(columns=[col for col in val if col==target or 'pred' in col]))\n",
        "val[[target]+[col for col in val.columns if 'pred' in col]]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bd6cebc3",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2024-01-04T21:04:01.618644Z",
          "start_time": "2024-01-04T21:04:01.270473400Z"
        },
        "id": "bd6cebc3"
      },
      "outputs": [],
      "source": [
        "model_name = regr.__str__()\n",
        "the_df = pd.concat([val, X_val['item_id']], axis=1)\n",
        "target_col = target\n",
        "the_metrics_df = metrics\n",
        "regression_metrics = None\n",
        "metrics = get_regression_metrics(the_df, target_col, pred_col, the_metrics_df, regression_metrics, model_name)\n",
        "metrics"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a06c26ee",
      "metadata": {
        "id": "a06c26ee"
      },
      "source": [
        "## LGBM grid search - no better resulsts"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ec1db8d4",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2024-01-04T21:08:22.133095800Z",
          "start_time": "2024-01-04T21:04:01.349690600Z"
        },
        "id": "ec1db8d4"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "# Define a parameter grid to search\n",
        "param_grid = {\n",
        "    'n_estimators': [100, 200, 300],\n",
        "    'learning_rate': [0.01, 0.05, 0.1],\n",
        "    'max_depth': [3, 5, 7],\n",
        "    # Add other parameters here\n",
        "}\n",
        "\n",
        "# Initialize the GridSearchCV object\n",
        "grid_search = GridSearchCV(estimator=lgbm, param_grid=param_grid, cv=3, scoring='neg_mean_squared_error')\n",
        "\n",
        "# Perform the grid search\n",
        "grid_search.fit(train.drop(columns=target), train[target])\n",
        "\n",
        "# Print the best parameters\n",
        "print(\"Best parameters found: \", grid_search.best_params_)\n",
        "\n",
        "# Use the best model for predictions\n",
        "best_model = grid_search.best_estimator_\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f001277c",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2024-01-04T21:08:22.733127900Z",
          "start_time": "2024-01-04T21:08:22.125725600Z"
        },
        "id": "f001277c"
      },
      "outputs": [],
      "source": [
        "best_model.score(train.drop(columns=target), train[target])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0149ba12",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2024-01-04T21:08:22.953568300Z",
          "start_time": "2024-01-04T21:08:22.725002900Z"
        },
        "id": "0149ba12"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Assuming 'rf_model' is your trained Random Forest model\n",
        "# and 'feature_names' is a list of your feature names\n",
        "\n",
        "# Get feature importances\n",
        "importances = best_model.feature_importances_\n",
        "\n",
        "# Create a DataFrame for easier handling\n",
        "feature_importances = pd.DataFrame({'Feature': features, 'Importance': importances})\n",
        "\n",
        "# Sort by importance\n",
        "feature_importances = feature_importances.sort_values(by='Importance', ascending=False)\n",
        "\n",
        "feature_importances = feature_importances.head(20)\n",
        "# Plot\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.barh(feature_importances['Feature'], feature_importances['Importance'])\n",
        "plt.xlabel('Importance')\n",
        "plt.ylabel('Feature')\n",
        "plt.title(f'LGBM grid searched Feature Importances')\n",
        "plt.gca().invert_yaxis()  # To display the highest importance at the top\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6cc96c51",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2024-01-04T21:08:23.153206700Z",
          "start_time": "2024-01-04T21:08:22.953568300Z"
        },
        "id": "6cc96c51"
      },
      "outputs": [],
      "source": [
        "pred_col = f'{target}_pred_{best_model.__str__()}'\n",
        "val[pred_col] = best_model.predict(val.drop(columns=[col for col in val if col==target or 'pred' in col]))\n",
        "val[[target]+[col for col in val.columns if 'pred' in col]]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "89ed7e1b",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2024-01-04T21:08:23.332838700Z",
          "start_time": "2024-01-04T21:08:23.137795100Z"
        },
        "id": "89ed7e1b"
      },
      "outputs": [],
      "source": [
        "model_name = best_model.__str__()\n",
        "the_df = pd.concat([val, X_val['item_id']], axis=1)\n",
        "target_col = target\n",
        "the_metrics_df = metrics\n",
        "regression_metrics = None\n",
        "metrics = get_regression_metrics(the_df, target_col, pred_col, the_metrics_df, regression_metrics, model_name)\n",
        "metrics"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "817379dc",
      "metadata": {
        "id": "817379dc"
      },
      "source": [
        "## Final try - Random Forest grid search max_depth (grid search on all is too slow, LGBM much more efficient)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0ac12c44",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2024-01-04T22:23:06.975709900Z",
          "start_time": "2024-01-04T22:05:16.315328700Z"
        },
        "id": "0ac12c44"
      },
      "outputs": [],
      "source": [
        "from sklearn.ensemble import RandomForestRegressor\n",
        "# Range of max_depth values to explore\n",
        "max_max_depth = 31\n",
        "max_depth_range = np.arange(3, max_max_depth, 3)  # 1 to 30\n",
        "\n",
        "for max_depth in max_depth_range:\n",
        "    print(f\"max_depth: {max_depth}/{max_max_depth}\")\n",
        "    regr = RandomForestRegressor(max_depth=max_depth, random_state=0, n_jobs=-1)\n",
        "    regr.fit(train.drop(columns=target), train[target])\n",
        "    print(regr.score(train.drop(columns=target), train[target]))\n",
        "    pred_col = f'{target}_pred_{regr.__str__()}'\n",
        "    val[pred_col] = regr.predict(val.drop(columns=[col for col in val if col==target or 'pred' in col]))\n",
        "    model_name = regr.__str__()\n",
        "    the_df = pd.concat([val, X_val['item_id']], axis=1)\n",
        "    target_col = target\n",
        "    the_metrics_df = metrics\n",
        "    regression_metrics = None\n",
        "    metrics = get_regression_metrics(the_df, target_col, pred_col, the_metrics_df, regression_metrics, model_name)\n",
        "metrics"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7db2b729",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2024-01-04T22:26:51.686584800Z",
          "start_time": "2024-01-04T22:26:51.106138200Z"
        },
        "id": "7db2b729"
      },
      "outputs": [],
      "source": [
        "metrics.reset_index().drop_duplicates(subset='index')[['index','mean_absolute_error']].sort_values(by='mean_absolute_error')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2e55f978",
      "metadata": {
        "id": "2e55f978"
      },
      "source": [
        "## We'll choose max_depth=None as it has the minimum mean absolute error."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b18700f2",
      "metadata": {
        "id": "b18700f2"
      },
      "source": [
        "## The basline model does have a lower MSE (less ratings with larger errors), but higher MAE (generally worse the RF), and there's also no practical way to use it - it essetinailly predicts the same fixed number of rating for all items the user might choose."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "678de675",
      "metadata": {
        "id": "678de675"
      },
      "source": [
        "# Model Validation on test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7823f02b",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2024-01-04T22:38:18.889722900Z",
          "start_time": "2024-01-04T22:38:18.441855200Z"
        },
        "id": "7823f02b"
      },
      "outputs": [],
      "source": [
        "train['rating_pred_baseline']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a3c2bb22",
      "metadata": {
        "id": "a3c2bb22"
      },
      "outputs": [],
      "source": [
        "from sklearn.ensemble import RandomForestRegressor\n",
        "\n",
        "regr = RandomForestRegressor(random_state=0, n_jobs=-1)\n",
        "regr.fit(train.drop(columns=target), train[target])\n",
        "print(regr.score(train.drop(columns=target), train[target]))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4e916fc0",
      "metadata": {
        "id": "4e916fc0"
      },
      "source": [
        "## MAE is higher, as suspected, RF max_depth=None is overfitting... might also be a feature selection issue. But not time to explore :( hopefully retraining on entire dataset mitigate a little."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c91f9078",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2024-01-04T22:44:30.523904700Z",
          "start_time": "2024-01-04T22:44:30.043069600Z"
        },
        "id": "c91f9078"
      },
      "outputs": [],
      "source": [
        "\n",
        "test[pred_col] = regr.predict(test.drop(columns=[col for col in test.columns if col==target or 'pred' in col]))\n",
        "model_name = f'test_{regr.__str__()}'\n",
        "X_test.index = test.index\n",
        "the_df = pd.concat([test, X_test['item_id']], axis=1)\n",
        "target_col = target\n",
        "the_metrics_df = metrics\n",
        "regression_metrics = None\n",
        "metrics = get_regression_metrics(the_df, target_col, pred_col, the_metrics_df, regression_metrics, model_name)\n",
        "metrics"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0aabd0fe",
      "metadata": {
        "id": "0aabd0fe"
      },
      "source": [
        "# Retrain on all data and save to pickle, save metrics to csv"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7902bb7c",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2024-01-04T22:47:02.913538800Z",
          "start_time": "2024-01-04T22:47:02.640058700Z"
        },
        "id": "7902bb7c"
      },
      "outputs": [],
      "source": [
        "# Create Entire dataset: train + validation + test\n",
        "df = pd.concat([train, val[train.columns], test[train.columns]], axis=0)\n",
        "assert df.isna().sum().sum() == 0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "563e3ed4",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2024-01-04T22:49:30.695263200Z",
          "start_time": "2024-01-04T22:49:30.193740300Z"
        },
        "id": "563e3ed4"
      },
      "outputs": [],
      "source": [
        "df.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "279016fb",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2024-01-04T22:55:53.933675Z",
          "start_time": "2024-01-04T22:50:28.868214Z"
        },
        "id": "279016fb"
      },
      "outputs": [],
      "source": [
        "from sklearn.ensemble import RandomForestRegressor\n",
        "\n",
        "regr = RandomForestRegressor(random_state=0, n_jobs=-1)\n",
        "regr.fit(df.drop(columns=target), df[target])\n",
        "print(regr.score(df.drop(columns=target), df[target]))\n",
        "\n",
        "# Get feature importances\n",
        "importances = regr.feature_importances_\n",
        "\n",
        "# Create a DataFrame for easier handling\n",
        "feature_importances = pd.DataFrame({'Feature': features, 'Importance': importances})\n",
        "\n",
        "# Sort by importance\n",
        "feature_importances = feature_importances.sort_values(by='Importance', ascending=False)\n",
        "\n",
        "feature_importances_top = feature_importances.head(20)\n",
        "# Plot\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.barh(feature_importances_top['Feature'], feature_importances_top['Importance'])\n",
        "plt.xlabel('Importance')\n",
        "plt.ylabel('Feature')\n",
        "plt.title('Random Forest Feature Importances on entire dataset')\n",
        "plt.gca().invert_yaxis()  # To display the highest importance at the top\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5fdf75ca",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2024-01-04T22:57:07.344982200Z",
          "start_time": "2024-01-04T22:57:06.604138400Z"
        },
        "id": "5fdf75ca"
      },
      "outputs": [],
      "source": [
        "print(\"This is our current trained production model:\")\n",
        "print(regr)\n",
        "\n",
        "filename='amazon_recommendation_RF_model.pickle'\n",
        "save_model_to_pickle(regr, filename)\n",
        "\n",
        "metrics.to_excel(\"models_metrics.xlsx\")\n",
        "print(\"Finished training pipeline!\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "dd58350f",
      "metadata": {
        "id": "dd58350f"
      },
      "source": [
        "# How to make predictions in production"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cf2c9f3d",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2024-01-04T23:14:09.789655500Z",
          "start_time": "2024-01-04T23:14:09.207697700Z"
        },
        "id": "cf2c9f3d"
      },
      "outputs": [],
      "source": [
        "df['item_id'] = pd.concat([X_train['item_id'], X_val['item_id'], X_test['item_id']], axis=0, ignore_index=True).values"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "06c91c45",
      "metadata": {
        "id": "06c91c45"
      },
      "source": [
        "## our features are divided by item and user specific features, all can be queried from df,\n",
        "## and similarity features, which should be calculated on demand using the user similarity matrix, as in \"Add collaborative filtering features\" above.\n",
        "## However, we will only consider for prediction items that were their share of ratings out of total rating is at least 0.1% - and so we'll precompute all similarity features using all users and these highly rated set of items  \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "adc29751",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2024-01-04T23:47:11.362466900Z",
          "start_time": "2024-01-04T23:47:10.828425500Z"
        },
        "id": "adc29751"
      },
      "outputs": [],
      "source": [
        "highly_rated_items = df['item_id'].value_counts(normalize=True)[df['item_id'].value_counts(normalize=True)>0.001].index.to_list()\n",
        "highly_rated_items"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "024214ea",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2024-01-04T23:28:11.653724300Z",
          "start_time": "2024-01-04T23:28:10.993616900Z"
        },
        "id": "024214ea"
      },
      "outputs": [],
      "source": [
        "df = df.reset_index()\n",
        "df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1d37ea5d",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2024-01-04T23:42:18.589891900Z",
          "start_time": "2024-01-04T23:42:17.149619500Z"
        },
        "id": "1d37ea5d"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Get unique users\n",
        "unique_users = df['userName'].unique()\n",
        "\n",
        "# Create a DataFrame from highly_rated_items\n",
        "highly_rated_df = pd.DataFrame(highly_rated_items, columns=['item_id'])\n",
        "\n",
        "# Create a DataFrame for all unique users\n",
        "users_df = pd.DataFrame(unique_users, columns=['userName'])\n",
        "\n",
        "# Perform Cartesian product\n",
        "cartesian_product_df = users_df.assign(key=1).merge(highly_rated_df.assign(key=1), on='key').drop('key', axis=1)\n",
        "\n",
        "# Drop pairs that already exist in df\n",
        "new_pairs_df = cartesian_product_df[~cartesian_product_df.set_index(['userName', 'item_id']).index.isin(df.set_index(['userName', 'item_id']).index)]\n",
        "\n",
        "# Now, new_pairs_df contains all new combinations of userName and highly rated item_ids"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b2759256",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2024-01-04T23:42:18.651703700Z",
          "start_time": "2024-01-04T23:42:18.584879400Z"
        },
        "id": "b2759256"
      },
      "outputs": [],
      "source": [
        "new_pairs_df"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0db618bd",
      "metadata": {
        "id": "0db618bd"
      },
      "source": [
        "## we created all possible pair of users and items. Now let's add their user and item specific features, and calculate their similarity features."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "309d3182",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2024-01-04T23:42:21.267828500Z",
          "start_time": "2024-01-04T23:42:21.101974300Z"
        },
        "id": "309d3182"
      },
      "outputs": [],
      "source": [
        "user_cols = [col for col in df.columns if 'user' in col if 'sim' not in col]\n",
        "user_cols"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f1542a07",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2024-01-04T23:42:25.395104600Z",
          "start_time": "2024-01-04T23:42:24.659804700Z"
        },
        "id": "f1542a07"
      },
      "outputs": [],
      "source": [
        "user_specific_features = df.drop_duplicates('userName')[user_cols]\n",
        "user_specific_features"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "78414aa2",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2024-01-04T23:42:26.434475800Z",
          "start_time": "2024-01-04T23:42:25.480369500Z"
        },
        "id": "78414aa2"
      },
      "outputs": [],
      "source": [
        "new_pairs_df = new_pairs_df.merge(user_specific_features, on=['userName'], how='left')\n",
        "new_pairs_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e9161f3d",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2024-01-04T23:44:43.269781400Z",
          "start_time": "2024-01-04T23:44:42.737881300Z"
        },
        "id": "e9161f3d"
      },
      "outputs": [],
      "source": [
        "item_cols = [col for col in df.columns if col.startswith('item') or col.startswith('brand') or col.startswith('category') if 'sim' not in col]\n",
        "item_cols"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8814c431",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2024-01-04T23:44:58.504519300Z",
          "start_time": "2024-01-04T23:44:58.145469400Z"
        },
        "id": "8814c431"
      },
      "outputs": [],
      "source": [
        "item_specific_features = move_cols_to_first(df.drop_duplicates('item_id')[item_cols], ['item_id'])\n",
        "item_specific_features"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "81b00e19",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2024-01-04T23:45:08.049423100Z",
          "start_time": "2024-01-04T23:45:07.321158400Z"
        },
        "id": "81b00e19"
      },
      "outputs": [],
      "source": [
        "new_pairs_df = new_pairs_df.merge(item_specific_features, on=['item_id'], how='left')\n",
        "new_pairs_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "76d1fb6e",
      "metadata": {
        "id": "76d1fb6e"
      },
      "outputs": [],
      "source": [
        "[col for col in train.columns if col not in new_pairs_df.columns]"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6412a48a",
      "metadata": {
        "id": "6412a48a"
      },
      "source": [
        "## We're only missing similarity cols, let's create them using similar_users_dict and the df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "17890126",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2024-01-04T23:52:01.730686500Z",
          "start_time": "2024-01-04T23:47:28.147236Z"
        },
        "id": "17890126"
      },
      "outputs": [],
      "source": [
        "chunk_size = 1000\n",
        "new_pairs_df = process_in_chunks(new_pairs_df, similar_users_dict, df, features, chunk_size=chunk_size)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3fc5b546",
      "metadata": {
        "id": "3fc5b546"
      },
      "source": [
        "# This will take too long - and those features are not the most important ones...\n",
        "# I'll retrain the model without the 6 similarity features!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "04e6f948",
      "metadata": {
        "id": "04e6f948"
      },
      "outputs": [],
      "source": [
        "from sklearn.ensemble import RandomForestRegressor\n",
        "\n",
        "regr = RandomForestRegressor(random_state=0, n_jobs=-1)\n",
        "regr.fit(df.drop(columns=[col for col in train.columns if col not in new_pairs_df.columns] + ['userName','item_id']), df[target])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "83b72a01",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2024-01-05T00:06:44.558312800Z",
          "start_time": "2024-01-05T00:06:43.031855300Z"
        },
        "id": "83b72a01"
      },
      "outputs": [],
      "source": [
        "print(regr.score(df.drop(columns=[col for col in train.columns if col not in new_pairs_df.columns] + ['userName','item_id']), df[target]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "96698577",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2024-01-05T00:07:25.402327100Z",
          "start_time": "2024-01-05T00:07:24.662928Z"
        },
        "id": "96698577"
      },
      "outputs": [],
      "source": [
        "df_features = df.drop(columns=[col for col in train.columns if col not in new_pairs_df.columns] + ['userName','item_id']).columns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "69fcf3a8",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2024-01-05T00:07:53.486626600Z",
          "start_time": "2024-01-05T00:07:49.553009200Z"
        },
        "id": "69fcf3a8"
      },
      "outputs": [],
      "source": [
        "new_pairs_df[target] = regr.predict(new_pairs_df[df_features])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c7f0a82f",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2024-01-05T00:20:05.612876Z",
          "start_time": "2024-01-05T00:17:52.955396200Z"
        },
        "id": "c7f0a82f"
      },
      "outputs": [],
      "source": [
        "new_pairs_df.to_csv('user_item_recommendations_ratings_and_features.csv', index=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3a9da129",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2024-01-05T00:08:24.847852300Z",
          "start_time": "2024-01-05T00:08:24.159022200Z"
        },
        "id": "3a9da129"
      },
      "outputs": [],
      "source": [
        "new_pairs_df[['userName','item_id','rating']]"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "bfcd07e1",
      "metadata": {
        "id": "bfcd07e1"
      },
      "source": [
        "## filter the top 5 recommendations per user"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e910d3a3",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2024-01-05T00:14:44.756281800Z",
          "start_time": "2024-01-05T00:14:17.797616500Z"
        },
        "id": "e910d3a3"
      },
      "outputs": [],
      "source": [
        "# Group by 'userName' and get the top 5 'rating' for each 'userName'\n",
        "top_5_rated_per_user = df.groupby('userName').apply(lambda x: x.nlargest(5, 'rating')).reset_index(drop=True)[['userName','item_id','rating']]\n",
        "top_5_rated_per_user"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6261d6dc",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2024-01-05T00:15:34.066584700Z",
          "start_time": "2024-01-05T00:15:33.474179500Z"
        },
        "id": "6261d6dc"
      },
      "outputs": [],
      "source": [
        "assert top_5_rated_per_user[target].mean() > new_pairs_df[target].mean()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cee0601b",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2024-01-05T00:17:46.075507400Z",
          "start_time": "2024-01-05T00:17:45.456954100Z"
        },
        "id": "cee0601b"
      },
      "outputs": [],
      "source": [
        "top_5_rated_per_user.to_csv('user_item_top_5_recommendations_by_ratings.csv', index=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7124a712",
      "metadata": {
        "id": "7124a712"
      },
      "source": [
        "## save top 5 items for new users or users with not enough ratings (were dropped in the begining)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "142af6ae",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2024-01-05T00:26:12.196484600Z",
          "start_time": "2024-01-05T00:26:11.542603500Z"
        },
        "id": "142af6ae"
      },
      "outputs": [],
      "source": [
        "most_popular_items_per_category = pd.concat([X_train[['item_id','category']], X_val[['item_id','category']], X_test[['item_id','category']]], axis=0, ignore_index=True).reset_index().groupby(['item_id','category']).size().sort_values(ascending=False).reset_index().drop_duplicates(subset=['category'], keep='first')\n",
        "most_popular_items_per_category =  most_popular_items_per_category[:5].item_id.str.split('_', expand=True)\n",
        "most_popular_items_per_category.columns = ['brand','itemName', 'price']\n",
        "most_popular_items_per_category = move_cols_to_first(most_popular_items_per_category, ['itemName'])\n",
        "most_popular_items_per_category = most_popular_items_per_category.reset_index(drop=True)\n",
        "most_popular_items_per_category"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2f41c0e5",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2024-01-05T00:26:34.295402100Z",
          "start_time": "2024-01-05T00:26:34.134950100Z"
        },
        "id": "2f41c0e5"
      },
      "outputs": [],
      "source": [
        "most_popular_items_per_category.to_csv('most_popular_items_per_category.csv', index=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "73e9cabc",
      "metadata": {
        "id": "73e9cabc"
      },
      "source": [
        "## The final logic of the app"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "81e53922",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2024-01-05T00:30:30.118982500Z",
          "start_time": "2024-01-05T00:30:29.487416900Z"
        },
        "id": "81e53922"
      },
      "outputs": [],
      "source": [
        "top_5_rated_per_user = pd.read_csv('user_item_top_5_recommendations_by_ratings.csv')\n",
        "most_popular_items_per_category = pd.read_csv('most_popular_items_per_category.csv')\n",
        "\n",
        "def get_item_recommendations_for_userName(userName):\n",
        "    recommended_items = top_5_rated_per_user.loc[top_5_rated_per_user['userName'] == userName, 'item_id'].str.split('_', expand=True)\n",
        "    if len(recommended_items) > 0:\n",
        "        recommended_items.columns = ['brand','itemName', 'price']\n",
        "        recommended_items = move_cols_to_first(recommended_items, ['itemName'])\n",
        "        recommended_items = recommended_items.reset_index(drop=True)\n",
        "    else:\n",
        "        recommended_items = most_popular_items_per_category\n",
        "\n",
        "    return recommended_items\n",
        "\n",
        "userName = 'Boo'\n",
        "get_item_recommendations_for_userName(userName)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.4"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}